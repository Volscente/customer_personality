{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a8425c-154a-42b2-8e92-2b6c68dfcaba",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The notebook is intended to perform a binary classification over the 'Response' label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f217cfae-abee-40ce-8e84-33c6ffc96f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Set Pandas Options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97637c10-2df0-42a5-b62d-e44b32f0cc2e",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "722fbeee-0d35-456e-b2eb-1ca975bf123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = pd.read_csv('./../data/marketing_campaign_prepared.csv', encoding='latin1', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57b099-f6af-48e5-bd73-cde46dfe71a1",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4c6ac-994e-4b64-a414-616b0203e158",
   "metadata": {},
   "source": [
    "## Features & Label Definition\n",
    "\n",
    "The 'ID' column does not bring any useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd5e56e-960b-4a19-b6fc-703308de3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x and y\n",
    "X = data.drop(['ID', 'Response'], axis=1)\n",
    "y = data['Response']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b089fd86-88fc-4206-a612-788601a7a8fe",
   "metadata": {},
   "source": [
    "## Train & Test Split\n",
    "\n",
    "Since the label is characterized by a strong imbalancing in the class distribution, we need to address it carefully:\n",
    "1. Ensure that the training and test sets have the same proportions of the two classes\n",
    "2. Oversample the minor class (i.e., randomly duplicate examples)\n",
    "3. Undersample the major class (i.e., randomly delete examples)\n",
    "4. Use several metrics (e.g., Accuracy, Precision, Recall, AUC)\n",
    "\n",
    "Use StratifiedShuffleSplit. This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.\n",
    "\n",
    "Note: like the ShuffleSplit strategy, stratified random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a986abb-2a63-4ae7-9333-7a4cfe292b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard train & test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d2ff9b-1d55-4179-baef-ec46a29497fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the a Stratified K-fold Shuffle Splitter\n",
    "stratified_kfold = StratifiedShuffleSplit(n_splits=10,\n",
    "                                          test_size=.3, \n",
    "                                          random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f892767-69de-442b-bcb5-1be134ee12b9",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a14a67-8eba-41dd-9c58-4ac2dd190bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Features\n",
    "numerical_features = ['Year_Birth', \n",
    "                      'Income', \n",
    "                      'Recency', \n",
    "                      'MntWines', \n",
    "                      'MntFruits', \n",
    "                      'MntMeatProducts', \n",
    "                      'MntFishProducts', \n",
    "                      'MntSweetProducts', \n",
    "                      'MntGoldProds', \n",
    "                      'NumDealsPurchases', \n",
    "                      'NumWebPurchases', \n",
    "                      'NumCatalogPurchases', \n",
    "                      'NumStorePurchases', \n",
    "                      'NumWebVisitsMonth']\n",
    "\n",
    "# Categorical Text Features\n",
    "categorical_text_features = ['Education', \n",
    "                             'Marital_Status']\n",
    "\n",
    "# Categorical Numerical Features\n",
    "categorical_numerical_features = ['Kidhome', \n",
    "                                  'Teenhome', \n",
    "                                  'AcceptedCmp1', \n",
    "                                  'AcceptedCmp2', \n",
    "                                  'AcceptedCmp3', \n",
    "                                  'AcceptedCmp4', \n",
    "                                  'AcceptedCmp5', \n",
    "                                  'Complain', \n",
    "                                  'Dt_Customer_month', \n",
    "                                  'Dt_Customer_dayofweek']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03838419-b05d-4243-be09-3aa6582a269b",
   "metadata": {},
   "source": [
    "## Data Standardization\n",
    "\n",
    "Transform the individual features to look more or less like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "\n",
    "Keep in mind that tree-based methods are scale-invariant, so data standardization is not required.\n",
    "\n",
    "Standardization has to go after training-test split. That's because, standardizing the whole dataset and then split, would introduce into the training set some information about the mean and std of the test set. Remember to standardize the test set with the same scaler trained on the training set. This would be addressed by constructing a pipeline with the scaler as a step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a81e3ad1-409c-44d1-892b-b8a02761ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ColumnTransformer\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('numerical', StandardScaler(), numerical_features),\n",
    "    ('categorical_text', OneHotEncoder(), categorical_text_features),\n",
    "    ('categorical_numerical', 'passthrough', categorical_numerical_features)\n",
    "], verbose_feature_names_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2436ba73-ed02-4d14-a0ee-176c21df6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the ColumnTransformer\n",
    "_ = column_transformer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d2627fd-62f7-4eb0-8b1a-138c454cafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the columns\n",
    "X_train_transformed = pd.DataFrame(column_transformer.transform(X_train), columns=column_transformer.get_feature_names_out())\n",
    "X_test_transformed = pd.DataFrame(column_transformer.transform(X_test), columns=column_transformer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde34e9-b215-44fe-be01-b8d6a82fd2d0",
   "metadata": {},
   "source": [
    "# Models Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11486f6f-b209-440b-bfef-7105de231729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary of model performance\n",
    "performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15567a9-a6c1-416e-b76f-1e54dcb60d31",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "First benchmark model. Use standard train & test split and fit the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e034d5af-cc3d-47ee-b360-b6eea8947347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Train the model\n",
    "model_lr.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions_lr = model_lr.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c6b993-199a-4c28-8686-219126c8c859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 90.12%\n",
      "Model precision: 53.85%\n",
      "Model recall: 26.92%\n",
      "Model f1 score: 35.9%\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "accuracy_lr = round(accuracy_score(y_test, predictions_lr) * 100, 2)\n",
    "precision_lr = round(precision_score(y_test, predictions_lr) * 100, 2)\n",
    "recall_lr = round(recall_score(y_test, predictions_lr) * 100, 2)\n",
    "f1_lr = round(f1_score(y_test, predictions_lr) * 100, 2)\n",
    "\n",
    "print('Model accuracy: {}%'.format(accuracy_lr))\n",
    "print('Model precision: {}%'.format(precision_lr))\n",
    "print('Model recall: {}%'.format(recall_lr))\n",
    "print('Model f1 score: {}%'.format(f1_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7198df42-8b33-43c8-8555-118df8e148da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' dictionary\n",
    "performance['logistic_regression'] = {\n",
    "    'accuracy': 0,\n",
    "    'precision': 0,\n",
    "    'recall': 0,\n",
    "    'f1': 0\n",
    "}\n",
    "performance['logistic_regression']['accuracy'] = accuracy_lr\n",
    "performance['logistic_regression']['precision'] = precision_lr\n",
    "performance['logistic_regression']['recall'] = recall_lr\n",
    "performance['logistic_regression']['f1'] = f1_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cd5fa-ce62-44ea-b455-0be54e92257d",
   "metadata": {},
   "source": [
    "## Logistic Regression - Pipeline\n",
    "\n",
    "Use the same model as before, but within a pipeline (experimental purposes only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "291c8545-928a-4bb1-a6d3-906512cd1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_lr_pipe = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Define the pipeline\n",
    "lr_pipe = Pipeline([\n",
    "    ('feature_transformation', column_transformer),\n",
    "    ('logistic_regression', model_lr_pipe)\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions_lr_pipe = lr_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ace32f8-b1d1-4b88-9087-4631b94f6c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 90.12%\n",
      "Model precision: 53.85%\n",
      "Model recall: 26.92%\n",
      "Model f1 score: 35.9%\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "accuracy_lr_pipe = round(accuracy_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "precision_lr_pipe = round(precision_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "recall_lr_pipe = round(recall_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "f1_lr_pipe = round(f1_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "\n",
    "print('Model accuracy: {}%'.format(accuracy_lr_pipe))\n",
    "print('Model precision: {}%'.format(precision_lr_pipe))\n",
    "print('Model recall: {}%'.format(recall_lr_pipe))\n",
    "print('Model f1 score: {}%'.format(f1_lr_pipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd09d059-9c0e-4a2f-9009-2c1efc11f8a3",
   "metadata": {},
   "source": [
    "As expected, the results are exactly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545d4e2-d60c-426e-a2b0-1546673b1829",
   "metadata": {},
   "source": [
    "## Logistic Regression - Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd385c2-c6d1-4758-99dc-11b815e457f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 91.37%\n",
      "Model precision: 68.69%\n",
      "Model recall: 31.87%\n",
      "Model f1 score: 43.34%\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model_lr_cv = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Initialize metrics lists\n",
    "accuracy_lr_cv = []\n",
    "precision_lr_cv = []\n",
    "recall_lr_cv = []\n",
    "f1_lr_cv = []\n",
    "\n",
    "# Train the model with K-fold\n",
    "for train_index, test_index in stratified_kfold.split(X, y):\n",
    "    \n",
    "    # Define the pipeline\n",
    "    pipeline_lr_cv = Pipeline([\n",
    "        ('feature_transformation', column_transformer),\n",
    "        ('logistic_regression', model_lr_cv)\n",
    "    ])\n",
    "        \n",
    "    # Train the model\n",
    "    pipeline_lr_cv.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "\n",
    "    # Get predicitons\n",
    "    predictions_lr_cv = pipeline_lr_cv.predict(X.iloc[test_index])\n",
    "\n",
    "    # Model evaluation\n",
    "    accuracy_lr_cv.append(round(accuracy_score(y.iloc[test_index], predictions_lr_cv) * 100, 2))\n",
    "    precision_lr_cv.append(round(precision_score(y.iloc[test_index], predictions_lr_cv) * 100, 2))\n",
    "    recall_lr_cv.append(round(recall_score(y.iloc[test_index], predictions_lr_cv) * 100, 2))\n",
    "    f1_lr_cv.append(round(f1_score(y.iloc[test_index], predictions_lr_cv) * 100, 2))\n",
    "\n",
    "print('Model accuracy: {}%'.format(round(np.mean(accuracy_lr_cv), 2)))\n",
    "print('Model precision: {}%'.format(round(np.mean(precision_lr_cv), 2)))\n",
    "print('Model recall: {}%'.format(round(np.mean(recall_lr_cv), 2)))\n",
    "print('Model f1 score: {}%'.format(round(np.mean(f1_lr_cv), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f639ba0-6906-42fc-8bcf-fdfae5f87745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' dictionary\n",
    "performance['logistic_regression_cv'] = {\n",
    "    'accuracy': 0,\n",
    "    'precision': 0,\n",
    "    'recall': 0,\n",
    "    'f1': 0\n",
    "}\n",
    "performance['logistic_regression_cv']['accuracy'] = round(np.mean(accuracy_lr_cv), 2)\n",
    "performance['logistic_regression_cv']['precision'] = round(np.mean(precision_lr_cv), 2)\n",
    "performance['logistic_regression_cv']['recall'] = round(np.mean(recall_lr_cv), 2)\n",
    "performance['logistic_regression_cv']['f1'] = round(np.mean(f1_lr_cv), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445728ea-04ad-4ef7-bd62-8a76cc61c5de",
   "metadata": {},
   "source": [
    "## Bayesian Optimization with HYPEROPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72b12e-627c-47b6-96c2-e1fa1531f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Hyperparamters space for Hyperopt\n",
    "hyperopt_parameters_space = {\n",
    "    'max_depth': hp.quniform(\"max_depth\", 3, 40, 2),\n",
    "    'gamma': hp.uniform ('gamma', 1, 15),\n",
    "    'reg_alpha' : hp.quniform('reg_alpha', 40, 180, 1),\n",
    "    'reg_lambda' : hp.uniform('reg_lambda', 0, 1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 0, 60, 3),\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 3000, 10),\n",
    "    'seed': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926bca8-b0c3-4136-b7cf-55165266d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Objective Function\n",
    "def objective(space, column_transformer=column_transformer, cv=stratified_kfold, X=X, y=y, scoring='roc_auc'):\n",
    "    \n",
    "    # Create the estimator\n",
    "    clf=xgb.XGBClassifier(objective='binary:logistic',\n",
    "                          eval_metric='auc',\n",
    "                          n_estimators=int(space['n_estimators']), \n",
    "                          max_depth=int(space['max_depth']), \n",
    "                          gamma=space['gamma'],\n",
    "                          reg_alpha=int(space['reg_alpha']),\n",
    "                          min_child_weight=int(space['min_child_weight']),\n",
    "                          colsample_bytree=int(space['colsample_bytree']),\n",
    "                          use_label_encoder=False)\n",
    "    \n",
    "    # Define the Pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('feature_transformation', column_transformer), \n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    # Init accuracy and precision list for K-fold\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    \n",
    "    # Train the model with K-fold\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "    \n",
    "        # Train the model\n",
    "        pipeline.fit(X[train_index], y[train_index])\n",
    "\n",
    "        # Get predicitons\n",
    "        predictions = pipeline.predict(X[test_index])\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy.append(accuracy_score(y[test_index], predictions))\n",
    "        \n",
    "        # Calculate precision\n",
    "        precision.append(precision_score(y[test_index], predictions))\n",
    "                                  \n",
    "        \n",
    "    # Calculate the score\n",
    "    cv_score = cross_val_score(pipeline, X, y, cv=cv, scoring=scoring, n_jobs=1).mean()\n",
    "    accuracy_mean = accuracy.mean()\n",
    "    precision_score = precision.mean()\n",
    "    \n",
    "    print(cv_score)\n",
    "    print(accuracy_mean)\n",
    "    print(precision_score)\n",
    "                \n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f90003-c31f-4e11-a5f0-3c0fb4e209ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = fmin(fn=objective,\n",
    "                  space=hyperopt_parameters_space,\n",
    "                  algo=tpe.suggest,\n",
    "                  max_evals=50,\n",
    "                  trials=Trials())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d0845d-5081-4ab1-8d05-ec471b106ca6",
   "metadata": {},
   "source": [
    "# Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0926a19-8edd-4f90-b0fe-7020e925063c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\n    Invalid value of type 'numpy.float64' received for the 'x' property of histogram\n        Received value: 90.12\n\n    The 'x' property is an array that may be specified as a tuple,\n    list, numpy array, or pandas Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m performance\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric_name \u001b[38;5;129;01min\u001b[39;00m performance[model_name]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m----> 8\u001b[0m         figure\u001b[38;5;241m.\u001b[39madd_trace(\u001b[43mgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHistogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperformance\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/plotly/graph_objs/_histogram.py:3076\u001b[0m, in \u001b[0;36mHistogram.__init__\u001b[0;34m(self, arg, alignmentgroup, autobinx, autobiny, bingroup, cliponaxis, constraintext, cumulative, customdata, customdatasrc, error_x, error_y, histfunc, histnorm, hoverinfo, hoverinfosrc, hoverlabel, hovertemplate, hovertemplatesrc, hovertext, hovertextsrc, ids, idssrc, insidetextanchor, insidetextfont, legendgroup, legendgrouptitle, legendrank, marker, meta, metasrc, name, nbinsx, nbinsy, offsetgroup, opacity, orientation, outsidetextfont, selected, selectedpoints, showlegend, stream, text, textangle, textfont, textposition, textsrc, texttemplate, uid, uirevision, unselected, visible, x, xaxis, xbins, xcalendar, xhoverformat, xsrc, y, yaxis, ybins, ycalendar, yhoverformat, ysrc, **kwargs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m _v \u001b[38;5;241m=\u001b[39m x \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _v\n\u001b[1;32m   3075\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3076\u001b[0m     \u001b[38;5;28mself\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _v\n\u001b[1;32m   3077\u001b[0m _v \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxaxis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   3078\u001b[0m _v \u001b[38;5;241m=\u001b[39m xaxis \u001b[38;5;28;01mif\u001b[39;00m xaxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _v\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/plotly/basedatatypes.py:4827\u001b[0m, in \u001b[0;36mBasePlotlyType.__setitem__\u001b[0;34m(self, prop, value)\u001b[0m\n\u001b[1;32m   4823\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_array_prop(prop, value)\n\u001b[1;32m   4825\u001b[0m     \u001b[38;5;66;03m# ### Handle simple property ###\u001b[39;00m\n\u001b[1;32m   4826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4827\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4828\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;66;03m# Make sure properties dict is initialized\u001b[39;00m\n\u001b[1;32m   4830\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_props()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/plotly/basedatatypes.py:5171\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   5170\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5171\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m   5173\u001b[0m \u001b[38;5;66;03m# val is None\u001b[39;00m\n\u001b[1;32m   5174\u001b[0m \u001b[38;5;66;03m# -----------\u001b[39;00m\n\u001b[1;32m   5175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5176\u001b[0m     \u001b[38;5;66;03m# Check if we should send null update\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/plotly/basedatatypes.py:5166\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5163\u001b[0m validator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_validator(prop)\n\u001b[1;32m   5165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5166\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_coerce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   5168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_invalid:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/_plotly_utils/basevalidators.py:405\u001b[0m, in \u001b[0;36mDataArrayValidator.validate_coerce\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m    403\u001b[0m     v \u001b[38;5;241m=\u001b[39m to_scalar_or_list(v)\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_invalid_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m v\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/_plotly_utils/basevalidators.py:289\u001b[0m, in \u001b[0;36mBaseValidator.raise_invalid_val\u001b[0;34m(self, v, inds)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[1;32m    287\u001b[0m                 name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    290\u001b[0m             \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    Invalid value of type {typ} received for the '{name}' property of {pname}\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m        Received value: {v}\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m{valid_clr_desc}\"\"\"\u001b[39;00m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    295\u001b[0m                 name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    296\u001b[0m                 pname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_name,\n\u001b[1;32m    297\u001b[0m                 typ\u001b[38;5;241m=\u001b[39mtype_str(v),\n\u001b[1;32m    298\u001b[0m                 v\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrepr\u001b[39m(v),\n\u001b[1;32m    299\u001b[0m                 valid_clr_desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription(),\n\u001b[1;32m    300\u001b[0m             )\n\u001b[1;32m    301\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: \n    Invalid value of type 'numpy.float64' received for the 'x' property of histogram\n        Received value: 90.12\n\n    The 'x' property is an array that may be specified as a tuple,\n    list, numpy array, or pandas Series"
     ]
    }
   ],
   "source": [
    "# Plot the models' metrics\n",
    "figure = go.Figure()\n",
    "\n",
    "for model_name in performance.keys():\n",
    "    \n",
    "    for metric_name in performance[model_name].keys():\n",
    "        \n",
    "        figure.add_trace(go.Histogram(x=performance[model_name][metric_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f607642-d631-45d1-b290-58de8945ed52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
