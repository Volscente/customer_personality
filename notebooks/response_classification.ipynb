{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a8425c-154a-42b2-8e92-2b6c68dfcaba",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The notebook is intended to perform a binary classification over the 'Response' label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f217cfae-abee-40ce-8e84-33c6ffc96f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, roc_auc_score, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as ex\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# Set Pandas Options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97637c10-2df0-42a5-b62d-e44b32f0cc2e",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "722fbeee-0d35-456e-b2eb-1ca975bf123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = pd.read_csv('./../data/marketing_campaign_prepared.csv', encoding='latin1', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57b099-f6af-48e5-bd73-cde46dfe71a1",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4c6ac-994e-4b64-a414-616b0203e158",
   "metadata": {},
   "source": [
    "## Features & Label Definition\n",
    "\n",
    "The 'ID' column does not bring any useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd5e56e-960b-4a19-b6fc-703308de3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x and y\n",
    "X = data.drop(['ID', 'Response'], axis=1)\n",
    "y = data['Response']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b089fd86-88fc-4206-a612-788601a7a8fe",
   "metadata": {},
   "source": [
    "## Train & Test Split\n",
    "\n",
    "Since the label is characterized by a strong imbalancing in the class distribution, we need to address it carefully:\n",
    "1. Ensure that the training and test sets have the same proportions of the two classes\n",
    "2. Oversample the minor class (i.e., randomly duplicate examples)\n",
    "3. Undersample the major class (i.e., randomly delete examples)\n",
    "4. Use several metrics (e.g., Accuracy, Precision, Recall, AUC)\n",
    "\n",
    "Use StratifiedShuffleSplit. This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.\n",
    "\n",
    "Note: like the ShuffleSplit strategy, stratified random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a986abb-2a63-4ae7-9333-7a4cfe292b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard train & test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d2ff9b-1d55-4179-baef-ec46a29497fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the a Stratified K-fold Shuffle Splitter\n",
    "stratified_kfold = StratifiedShuffleSplit(n_splits=10,\n",
    "                                          test_size=.3, \n",
    "                                          random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f892767-69de-442b-bcb5-1be134ee12b9",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a14a67-8eba-41dd-9c58-4ac2dd190bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Features\n",
    "numerical_features = ['Year_Birth', \n",
    "                      'Income', \n",
    "                      'Recency', \n",
    "                      'MntWines', \n",
    "                      'MntFruits', \n",
    "                      'MntMeatProducts', \n",
    "                      'MntFishProducts', \n",
    "                      'MntSweetProducts', \n",
    "                      'MntGoldProds', \n",
    "                      'NumDealsPurchases', \n",
    "                      'NumWebPurchases', \n",
    "                      'NumCatalogPurchases', \n",
    "                      'NumStorePurchases', \n",
    "                      'NumWebVisitsMonth']\n",
    "\n",
    "# Categorical Text Features\n",
    "categorical_text_features = ['Education', \n",
    "                             'Marital_Status']\n",
    "\n",
    "# Categorical Numerical Features\n",
    "categorical_numerical_features = ['Kidhome', \n",
    "                                  'Teenhome', \n",
    "                                  'AcceptedCmp1', \n",
    "                                  'AcceptedCmp2', \n",
    "                                  'AcceptedCmp3', \n",
    "                                  'AcceptedCmp4', \n",
    "                                  'AcceptedCmp5', \n",
    "                                  'Complain', \n",
    "                                  'Dt_Customer_month', \n",
    "                                  'Dt_Customer_dayofweek']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03838419-b05d-4243-be09-3aa6582a269b",
   "metadata": {},
   "source": [
    "## Data Standardization\n",
    "\n",
    "Transform the individual features to look more or less like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "\n",
    "Keep in mind that tree-based methods are scale-invariant, so data standardization is not required.\n",
    "\n",
    "Standardization has to go after training-test split. That's because, standardizing the whole dataset and then split, would introduce into the training set some information about the mean and std of the test set. Remember to standardize the test set with the same scaler trained on the training set. This would be addressed by constructing a pipeline with the scaler as a step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a81e3ad1-409c-44d1-892b-b8a02761ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ColumnTransformer\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('numerical', StandardScaler(), numerical_features),\n",
    "    ('categorical_text', OneHotEncoder(), categorical_text_features),\n",
    "    ('categorical_numerical', 'passthrough', categorical_numerical_features)\n",
    "], verbose_feature_names_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2436ba73-ed02-4d14-a0ee-176c21df6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the ColumnTransformer\n",
    "_ = column_transformer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d2627fd-62f7-4eb0-8b1a-138c454cafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the columns\n",
    "X_train_transformed = pd.DataFrame(column_transformer.transform(X_train), columns=column_transformer.get_feature_names_out())\n",
    "X_test_transformed = pd.DataFrame(column_transformer.transform(X_test), columns=column_transformer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde34e9-b215-44fe-be01-b8d6a82fd2d0",
   "metadata": {},
   "source": [
    "# Models Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d816ea7-e83d-49db-acc0-b7b306114fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the used metrics\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'cv_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11486f6f-b209-440b-bfef-7105de231729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrame of model performance\n",
    "performance = pd.DataFrame(columns=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15567a9-a6c1-416e-b76f-1e54dcb60d31",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "First benchmark model. Use standard train & test split and fit the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e034d5af-cc3d-47ee-b360-b6eea8947347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Train the model\n",
    "model_lr.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions_lr = model_lr.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5c6b993-199a-4c28-8686-219126c8c859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 90.12%\n",
      "Model precision: 53.85%\n",
      "Model recall: 26.92%\n",
      "Model f1 score: 35.9%\n",
      "Model ROC AUC: 62.14%\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "accuracy_lr = round(accuracy_score(y_test, predictions_lr) * 100, 2)\n",
    "precision_lr = round(precision_score(y_test, predictions_lr) * 100, 2)\n",
    "recall_lr = round(recall_score(y_test, predictions_lr) * 100, 2)\n",
    "f1_lr = round(f1_score(y_test, predictions_lr) * 100, 2)\n",
    "roc_auc_lr = round(roc_auc_score(y_test, predictions_lr) * 100, 2)\n",
    "\n",
    "print('Model accuracy: {}%'.format(accuracy_lr))\n",
    "print('Model precision: {}%'.format(precision_lr))\n",
    "print('Model recall: {}%'.format(recall_lr))\n",
    "print('Model f1 score: {}%'.format(f1_lr))\n",
    "print('Model ROC AUC: {}%'.format(roc_auc_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cd5fa-ce62-44ea-b455-0be54e92257d",
   "metadata": {},
   "source": [
    "## Logistic Regression - Pipeline\n",
    "\n",
    "Use the same model as before, but within a pipeline (experimental purposes only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c9d675d-2d5a-4357-9936-bc92a2a1b23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 1\n"
     ]
    }
   ],
   "source": [
    "# Experiment name\n",
    "experiment_name_lr = 'Logistic Regression'\n",
    "\n",
    "# Retrieve MLFlow Experiment\n",
    "experiment_lr = mlflow.get_experiment_by_name(experiment_name_lr)\n",
    "\n",
    "# Checking if Experiment exists\n",
    "if experiment_lr is None:\n",
    "    \n",
    "    print('Creating MLFlow experiment')\n",
    "\n",
    "    # Create experiment\n",
    "    _ = mlflow.create_experiment(experiment_name_lr)\n",
    "\n",
    "    # Retrieve experiment\n",
    "    experiment_lr = mlflow.get_experiment_by_name(experiment_name_lr)\n",
    "    \n",
    "print('Experiment ID: ' + experiment_lr.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb484214-1f42-481b-812b-503e6cbbfdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's Hyperparameters\n",
    "max_iter_lr = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "291c8545-928a-4bb1-a6d3-906512cd1a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 90.12%\n",
      "Model precision: 53.85%\n",
      "Model recall: 26.92%\n",
      "Model f1 score: 35.9%\n",
      "Model ROC AUC: 62.14%\n",
      "Model Cross Validation score: 91.37%\n"
     ]
    }
   ],
   "source": [
    "# Start MLFlow Run\n",
    "with mlflow.start_run(experiment_id=experiment_lr.experiment_id):\n",
    "\n",
    "    # Define the model\n",
    "    model_lr_pipe = LogisticRegression(max_iter=max_iter_lr)\n",
    "\n",
    "    # Define the pipeline\n",
    "    lr_pipe = Pipeline([\n",
    "        ('feature_transformation', column_transformer),\n",
    "        ('logistic_regression', model_lr_pipe)\n",
    "    ])\n",
    "\n",
    "    # Train the pipeline\n",
    "    lr_pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    predictions_lr_pipe = lr_pipe.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy_lr_pipe = round(accuracy_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "    precision_lr_pipe = round(precision_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "    recall_lr_pipe = round(recall_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "    f1_lr_pipe = round(f1_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "    roc_auc_lr_pipe = round(roc_auc_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "    cv_score_lr_pipe = round(cross_val_score(lr_pipe, X, y, cv=stratified_kfold).mean() * 100, 2)\n",
    "    \n",
    "    print('Model accuracy: {}%'.format(accuracy_lr_pipe))\n",
    "    print('Model precision: {}%'.format(precision_lr_pipe))\n",
    "    print('Model recall: {}%'.format(recall_lr_pipe))\n",
    "    print('Model f1 score: {}%'.format(f1_lr_pipe))\n",
    "    print('Model ROC AUC: {}%'.format(roc_auc_lr_pipe))\n",
    "    print('Model Cross Validation score: {}%'.format(cv_score_lr_pipe))\n",
    "    \n",
    "    # MLFlow Log Model Hyperparameters and Metrics\n",
    "    mlflow.log_param('max_iter', max_iter_lr)\n",
    "    mlflow.log_metrics({'Accuracy': accuracy_lr_pipe,\n",
    "                        'Precision': precision_lr_pipe,\n",
    "                        'Recall': recall_lr_pipe,\n",
    "                        'F1 Score': f1_lr_pipe,\n",
    "                        'ROC AUC': roc_auc_lr_pipe,\n",
    "                        'CV Score': cv_score_lr_pipe})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "168ab3c7-4d79-4577-a0d2-5072886b2643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' DataFrame\n",
    "performance.loc['logistic_regression'] = [accuracy_lr_pipe, \n",
    "                                          precision_lr_pipe, \n",
    "                                          recall_lr_pipe, \n",
    "                                          f1_lr_pipe, \n",
    "                                          roc_auc_lr_pipe, \n",
    "                                          cv_score_lr_pipe]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545d4e2-d60c-426e-a2b0-1546673b1829",
   "metadata": {},
   "source": [
    "## Logistic Regression - Cross-Validation training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e9ea5ed-cee7-4059-9c74-35380b7af018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 2\n"
     ]
    }
   ],
   "source": [
    "# Experiment name\n",
    "experiment_name_lr_cv = 'Logistic Regression - Cross Validation'\n",
    "\n",
    "# Retrieve MLFlow Experiment\n",
    "experiment_lr_cv = mlflow.get_experiment_by_name(experiment_name_lr_cv)\n",
    "\n",
    "# Checking if Experiment exists\n",
    "if experiment_lr_cv is None:\n",
    "    \n",
    "    print('Creating MLFlow experiment')\n",
    "\n",
    "    # Create experiment\n",
    "    _ = mlflow.create_experiment(experiment_name_lr_cv)\n",
    "\n",
    "    # Retrieve experiment\n",
    "    experiment_lr_cv = mlflow.get_experiment_by_name(experiment_name_lr_cv)\n",
    "    \n",
    "print('Experiment ID: ' + experiment_lr_cv.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d3b0eb8-f635-490f-955a-7fa593603343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's Hyperparameters\n",
    "max_iter_lr_cv = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fd385c2-c6d1-4758-99dc-11b815e457f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 91.37%\n",
      "Model precision: 68.69%\n",
      "Model recall: 31.87%\n",
      "Model f1 score: 43.34%\n",
      "Model ROC AUC: 65.09%\n",
      "Model Cross Validation score: 91.37%\n"
     ]
    }
   ],
   "source": [
    "# Start MLFlow Run\n",
    "with mlflow.start_run(experiment_id=experiment_lr_cv.experiment_id):\n",
    "\n",
    "    # Define the model\n",
    "    model_lr_cv = LogisticRegression(max_iter=max_iter_lr_cv)\n",
    "\n",
    "    # Define the pipeline\n",
    "    pipeline_lr_cv = Pipeline([\n",
    "        ('feature_transformation', column_transformer),\n",
    "        ('logistic_regression', model_lr_cv)\n",
    "    ])\n",
    "\n",
    "    # Initialize metrics lists\n",
    "    accuracy_lr_cv_list = []\n",
    "    precision_lr_cv_list = []\n",
    "    recall_lr_cv_list = []\n",
    "    f1_lr_cv_list = []\n",
    "    roc_auc_lr_cv_list = []\n",
    "\n",
    "    # Train the model with K-fold\n",
    "    for train_index, test_index in stratified_kfold.split(X, y):\n",
    "\n",
    "        # Train the model\n",
    "        pipeline_lr_cv.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "\n",
    "        # Get predicitons\n",
    "        predictions_lr_cv = pipeline_lr_cv.predict(X.iloc[test_index])\n",
    "\n",
    "        # Model evaluation\n",
    "        accuracy_lr_cv_step = round(accuracy_score(y.iloc[test_index], predictions_lr_cv) * 100, 2)\n",
    "        precision_lr_cv_step = round(precision_score(y.iloc[test_index], predictions_lr_cv) * 100, 2)\n",
    "        recall_lr_cv_step = round(recall_score(y.iloc[test_index], predictions_lr_cv) * 100, 2)\n",
    "        f1_lr_cv_step = round(f1_score(y.iloc[test_index], predictions_lr_cv) * 100, 2)\n",
    "        roc_auc_lr_cv_step = round(roc_auc_score(y.iloc[test_index], predictions_lr_cv) * 100, 2)\n",
    "        \n",
    "        # Append Model Metrics\n",
    "        accuracy_lr_cv_list.append(accuracy_lr_cv_step)\n",
    "        precision_lr_cv_list.append(precision_lr_cv_step)\n",
    "        recall_lr_cv_list.append(recall_lr_cv_step)\n",
    "        f1_lr_cv_list.append(f1_lr_cv_step)\n",
    "        roc_auc_lr_cv_list.append(roc_auc_lr_cv_step)\n",
    "        \n",
    "        # MLFlow Log Model Metrics\n",
    "        mlflow.log_metrics({'Accuracy': accuracy_lr_cv_step,\n",
    "                            'Precision': precision_lr_cv_step,\n",
    "                            'Recall': recall_lr_cv_step,\n",
    "                            'F1 Score': f1_lr_cv_step,\n",
    "                            'ROC AUC': roc_auc_lr_cv_step})\n",
    "\n",
    "    # Compute average of metrics among the K-Folds\n",
    "    accuracy_lr_cv = round(np.mean(accuracy_lr_cv_list), 2)\n",
    "    precision_lr_cv = round(np.mean(precision_lr_cv_list), 2)\n",
    "    recall_lr_cv = round(np.mean(recall_lr_cv_list), 2)\n",
    "    f1_lr_cv = round(np.mean(f1_lr_cv_list), 2)\n",
    "    roc_auc_lr_cv = round(np.mean(roc_auc_lr_cv_list), 2)\n",
    "    cv_score_lr_cv = round(cross_val_score(pipeline_lr_cv, X, y, cv=stratified_kfold).mean() * 100, 2)\n",
    "\n",
    "    print('Model accuracy: {}%'.format(accuracy_lr_cv))\n",
    "    print('Model precision: {}%'.format(precision_lr_cv))\n",
    "    print('Model recall: {}%'.format(recall_lr_cv))\n",
    "    print('Model f1 score: {}%'.format(f1_lr_cv))\n",
    "    print('Model ROC AUC: {}%'.format(roc_auc_lr_cv))\n",
    "    print('Model Cross Validation score: {}%'.format(cv_score_lr_cv))\n",
    "    \n",
    "    # MLFlow Log Model Hyperparameters and Metrics\n",
    "    mlflow.log_param('max_iter', max_iter_lr_cv)\n",
    "    mlflow.log_metric('CV Score', cv_score_lr_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f639ba0-6906-42fc-8bcf-fdfae5f87745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' DataFrame\n",
    "performance.loc['logistic_regression_cv'] = [accuracy_lr_cv, \n",
    "                                             precision_lr_cv, \n",
    "                                             recall_lr_cv, \n",
    "                                             f1_lr_cv, \n",
    "                                             roc_auc_lr_cv, \n",
    "                                             cv_score_lr_cv]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d85317-00c6-4ed6-9445-035973ec0398",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55be53d-e74a-4032-97a8-c524f7c69d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_xbg_cv = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                                 eval_metric='auc',\n",
    "                                 n_estimators=300,\n",
    "                                 max_depth=8,\n",
    "                                 min_child_weight=5,\n",
    "                                 use_label_encoder=False)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_xgb_cv = Pipeline([\n",
    "    ('feature_transformation', column_transformer),\n",
    "    ('xgboost_classifier', model_xbg_cv)\n",
    "])\n",
    "\n",
    "# Initialize metrics lists\n",
    "accuracy_xgb_cv_list = []\n",
    "precision_xgb_cv_list = []\n",
    "recall_xgb_cv_list = []\n",
    "f1_xgb_cv_list = []\n",
    "roc_auc_xgb_cv_list = []\n",
    "\n",
    "# Train the model with K-fold\n",
    "for train_index, test_index in stratified_kfold.split(X, y):\n",
    "          \n",
    "    # Train the model\n",
    "    pipeline_xgb_cv.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "\n",
    "    # Get predicitons\n",
    "    predictions_xgb_cv = pipeline_xgb_cv.predict(X.iloc[test_index])\n",
    "\n",
    "    # Model evaluation\n",
    "    accuracy_xgb_cv_list.append(round(accuracy_score(y.iloc[test_index], predictions_xgb_cv) * 100, 2))\n",
    "    precision_xgb_cv_list.append(round(precision_score(y.iloc[test_index], predictions_xgb_cv) * 100, 2))\n",
    "    recall_xgb_cv_list.append(round(recall_score(y.iloc[test_index], predictions_xgb_cv) * 100, 2))\n",
    "    f1_xgb_cv_list.append(round(f1_score(y.iloc[test_index], predictions_xgb_cv) * 100, 2))\n",
    "    roc_auc_xgb_cv_list.append(round(roc_auc_score(y.iloc[test_index], predictions_xgb_cv) * 100, 2))\n",
    "    \n",
    "# Compute average of metrics among the K-Folds\n",
    "accuracy_xgb_cv = round(np.mean(accuracy_xgb_cv_list), 2)\n",
    "precision_xgb_cv = round(np.mean(precision_xgb_cv_list), 2)\n",
    "recall_xgb_cv = round(np.mean(recall_xgb_cv_list), 2)\n",
    "f1_xgb_cv = round(np.mean(f1_xgb_cv_list), 2)\n",
    "roc_auc_xgb_cv = round(np.mean(roc_auc_xgb_cv_list), 2)\n",
    "cv_score_xgb_cv = round(cross_val_score(pipeline_xgb_cv, X, y, cv=stratified_kfold).mean() * 100, 2)\n",
    "\n",
    "\n",
    "print('Model accuracy: {}%'.format(accuracy_xgb_cv))\n",
    "print('Model precision: {}%'.format(precision_xgb_cv))\n",
    "print('Model recall: {}%'.format(recall_xgb_cv))\n",
    "print('Model f1 score: {}%'.format(f1_xgb_cv))\n",
    "print('Model ROC AUC: {}%'.format(roc_auc_xgb_cv))\n",
    "print('Model Cross Validation score: {}%'.format(cv_score_xgb_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83461b3b-ad0f-4859-a2c4-8cf2cb1bbd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' DataFrame\n",
    "performance.loc['xgboost_classifier_cv'] = [accuracy_xgb_cv, \n",
    "                                            precision_xgb_cv, \n",
    "                                            recall_xgb_cv, \n",
    "                                            f1_xgb_cv, \n",
    "                                            roc_auc_xgb_cv, \n",
    "                                            cv_score_xgb_cv]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445728ea-04ad-4ef7-bd62-8a76cc61c5de",
   "metadata": {},
   "source": [
    "## XGBoost with HYPEROPT Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72b12e-627c-47b6-96c2-e1fa1531f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Hyperparamters space for Hyperopt\n",
    "hyperopt_parameters_space = {\n",
    "    'max_depth': hp.quniform(\"max_depth\", 3, 40, 2),\n",
    "    'gamma': hp.uniform ('gamma', 0, 1),\n",
    "    #'reg_alpha' : hp.quniform('reg_alpha', 40, 180, 1),\n",
    "    #'reg_lambda' : hp.uniform('reg_lambda', 0, 1),\n",
    "    #'colsample_bytree' : hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 0, 60, 3),\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 3000, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926bca8-b0c3-4136-b7cf-55165266d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Objective Function\n",
    "def objective(space, column_transformer=column_transformer, cv=stratified_kfold, X=X, y=y):\n",
    "    \n",
    "    # Create the estimator\n",
    "    clf=xgb.XGBClassifier(objective='binary:logistic',\n",
    "                          eval_metric='auc',\n",
    "                          n_estimators=int(space['n_estimators']), \n",
    "                          max_depth=int(space['max_depth']), \n",
    "                          gamma=space['gamma'],\n",
    "                          #reg_alpha=int(space['reg_alpha']),\n",
    "                          min_child_weight=int(space['min_child_weight']),\n",
    "                          #colsample_bytree=int(space['colsample_bytree']),\n",
    "                          use_label_encoder=False)\n",
    "    \n",
    "    # Define the Pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('feature_transformation', column_transformer), \n",
    "        ('classifier', clf)\n",
    "    ]) \n",
    "   \n",
    "    # Initialize losses lists\n",
    "    log_loss_list = []\n",
    "    \n",
    "    # Train the model with K-fold\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "    \n",
    "        # Train the model\n",
    "        pipeline.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "\n",
    "        # Get predicitons\n",
    "        predictions = pipeline.predict(X.iloc[test_index])\n",
    "        \n",
    "        # Model loss\n",
    "        log_loss_list.append(round(log_loss(y.iloc[test_index], predictions) * 100, 2))\n",
    "                                          \n",
    "    # Compute average of metrics among the K-Folds\n",
    "    log_loss_score = round(np.mean(log_loss_list), 2)\n",
    "           \n",
    "    return log_loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f90003-c31f-4e11-a5f0-3c0fb4e209ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Hyperparameters Tuning\n",
    "parameters_xgb_cv_hyperopt = fmin(fn=objective,\n",
    "                                  space=hyperopt_parameters_space,\n",
    "                                  algo=tpe.suggest,\n",
    "                                  max_evals=5,\n",
    "                                  trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8086ae-a188-47c9-8624-b54c1f5865b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model_xgb_cv_hyperopt = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                                          eval_metric='auc',\n",
    "                                          n_estimators=int(parameters_xgb_cv_hyperopt['n_estimators']),\n",
    "                                          max_depth=int(parameters_xgb_cv_hyperopt['max_depth']), \n",
    "                                          gamma=parameters_xgb_cv_hyperopt['gamma'],\n",
    "                                          #reg_alpha=int(parameters_xgb_cv_hyperopt['reg_alpha']),\n",
    "                                          min_child_weight=int(parameters_xgb_cv_hyperopt['min_child_weight']),\n",
    "                                          #colsample_bytree=int(parameters_xgb_cv_hyperopt['colsample_bytree']),\n",
    "                                          use_label_encoder=False)\n",
    "# Define the pipeline\n",
    "pipeline_xgb_cv_hyperopt = Pipeline([\n",
    "    ('feature_transformation', column_transformer),\n",
    "    ('xgboost_classifier', model_xgb_cv_hyperopt)\n",
    "])\n",
    "\n",
    "# Initialize metrics lists\n",
    "accuracy_xgb_cv_hyperopt_list = []\n",
    "precision_xgb_cv_hyperopt_list = []\n",
    "recall_xgb_cv_hyperopt_list = []\n",
    "f1_xgb_cv_hyperopt_list = []\n",
    "roc_auc_xgb_cv_hyperopt_list = []\n",
    "\n",
    "# Train the model with K-fold\n",
    "for train_index, test_index in stratified_kfold.split(X, y):\n",
    "        \n",
    "    # Train the model\n",
    "    pipeline_xgb_cv_hyperopt.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "\n",
    "    # Get predicitons\n",
    "    predictions_xgb_cv_hyperopt = pipeline_xgb_cv_hyperopt.predict(X.iloc[test_index])\n",
    "\n",
    "    # Model evaluation\n",
    "    accuracy_xgb_cv_hyperopt_list.append(round(accuracy_score(y.iloc[test_index], predictions_xgb_cv_hyperopt) * 100, 2))\n",
    "    precision_xgb_cv_hyperopt_list.append(round(precision_score(y.iloc[test_index], predictions_xgb_cv_hyperopt) * 100, 2))\n",
    "    recall_xgb_cv_hyperopt_list.append(round(recall_score(y.iloc[test_index], predictions_xgb_cv_hyperopt) * 100, 2))\n",
    "    f1_xgb_cv_hyperopt_list.append(round(f1_score(y.iloc[test_index], predictions_xgb_cv_hyperopt) * 100, 2))\n",
    "    roc_auc_xgb_cv_hyperopt_list.append(round(roc_auc_score(y.iloc[test_index], predictions_xgb_cv_hyperopt) * 100, 2))\n",
    "    \n",
    "# Compute average of metrics among the K-Folds\n",
    "accuracy_xgb_cv_hyperopt = round(np.mean(accuracy_xgb_cv_hyperopt_list), 2)\n",
    "precision_xgb_cv_hyperopt = round(np.mean(precision_xgb_cv_hyperopt_list), 2)\n",
    "recall_xgb_cv_hyperopt = round(np.mean(recall_xgb_cv_hyperopt_list), 2)\n",
    "f1_xgb_cv_hyperopt = round(np.mean(f1_xgb_cv_hyperopt_list), 2)\n",
    "roc_auc_xgb_cv_hyperopt = round(np.mean(roc_auc_xgb_cv_hyperopt_list), 2)\n",
    "cv_score_xgb_cv_hyperopt = round(cross_val_score(pipeline_xgb_cv_hyperopt, X, y, cv=stratified_kfold).mean() * 100, 2)\n",
    "\n",
    "print('Model accuracy: {}%'.format(accuracy_xgb_cv_hyperopt))\n",
    "print('Model precision: {}%'.format(precision_xgb_cv_hyperopt))\n",
    "print('Model recall: {}%'.format(recall_xgb_cv_hyperopt))\n",
    "print('Model f1 score: {}%'.format(f1_xgb_cv_hyperopt))\n",
    "print('Model ROC AUC: {}%'.format(roc_auc_xgb_cv_hyperopt))\n",
    "print('Model Cross Validation score: {}%'.format(cv_score_xgb_cv_hyperopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8281618-380b-4c93-bccc-ea77aa590d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' DataFrame\n",
    "performance.loc['xgboost_classifier_cv_hyperopt'] = [accuracy_xgb_cv_hyperopt, \n",
    "                                                     precision_xgb_cv_hyperopt, \n",
    "                                                     recall_xgb_cv_hyperopt, \n",
    "                                                     f1_xgb_cv_hyperopt, \n",
    "                                                     roc_auc_xgb_cv_hyperopt, \n",
    "                                                     cv_score_xgb_cv_hyperopt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d6307-1feb-42a8-ba69-44c91c84aba9",
   "metadata": {},
   "source": [
    "## Dense Neural Network\n",
    "\n",
    "A TensorFlow-based DNN with CUDA GPU training and Hyperparameters Optimization.\n",
    "The objective is to compare XGBoost with Deep Learning.\n",
    "\n",
    "<br>\n",
    "\n",
    "**NOTE:** KerasClassifier is a wrapper to use Keras models with Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed8890-84c0-4e71-9d37-7e71e12b7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model structure and compile\n",
    "def create_baseline():\n",
    "    \n",
    "    # Define model\n",
    "    model_dnn_tf = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(34, input_shape=(None, 34), activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model_dnn_tf.compile(loss='binary_crossentropy', \n",
    "                         optimizer='adam', \n",
    "                         metrics=['accuracy'])\n",
    "    \n",
    "    return model_dnn_tf             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468bea4-a913-4326-bb05-c8a4d6ff2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Do not use the wrapper but transform the feature beforehand\n",
    "\n",
    "# Define model\n",
    "model_dnn_tf = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(34, input_shape=(None, 34), activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model_dnn_tf.compile(loss='binary_crossentropy', \n",
    "                     optimizer='adam', \n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b76b69-e9e2-4dc5-83c8-5b414e31cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the Keras model\n",
    "model_dnn_tf_wrapped = KerasClassifier(model=create_baseline, \n",
    "                                       epochs=20, \n",
    "                                       batch_size=5, \n",
    "                                       verbose=1)\n",
    "\n",
    "# Define the Pipeline\n",
    "pipeline_dnn_tf = Pipeline([\n",
    "    ('feature_transformation', column_transformer),\n",
    "    ('dnn_tf', model_dnn_tf_wrapped)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b542e40-3b29-4f60-86ae-3d8925aff8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "pipeline_dnn_tf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d0845d-5081-4ab1-8d05-ec471b106ca6",
   "metadata": {},
   "source": [
    "# Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0926a19-8edd-4f90-b0fe-7020e925063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the models' performance\n",
    "figure = ex.bar(performance,\n",
    "                x=performance.index,\n",
    "                y=performance.columns.values,\n",
    "                labels={'index': 'Model', 'value': 'Performance'},\n",
    "                barmode='group',\n",
    "                title='Models Comparison',\n",
    "                template='plotly_dark')\n",
    "\n",
    "figure.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
