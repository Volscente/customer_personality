{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a8425c-154a-42b2-8e92-2b6c68dfcaba",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The notebook is intended to perform a binary classification over the 'Response' label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f217cfae-abee-40ce-8e84-33c6ffc96f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Modules\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set Pandas Options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97637c10-2df0-42a5-b62d-e44b32f0cc2e",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "722fbeee-0d35-456e-b2eb-1ca975bf123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = pd.read_csv('./../data/marketing_campaign_prepared.csv', encoding='latin1', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57b099-f6af-48e5-bd73-cde46dfe71a1",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4c6ac-994e-4b64-a414-616b0203e158",
   "metadata": {},
   "source": [
    "## Features & Label Definition\n",
    "\n",
    "The 'ID' column does not bring any useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd5e56e-960b-4a19-b6fc-703308de3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x and y\n",
    "X = data.drop(['ID', 'Response'], axis=1)\n",
    "y = data['Response']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b089fd86-88fc-4206-a612-788601a7a8fe",
   "metadata": {},
   "source": [
    "## Train & Test Split\n",
    "\n",
    "Since the label is characterized by a strong imbalancing in the class distribution, we need to address it carefully:\n",
    "1. Ensure that the training and test sets have the same proportions of the two classes\n",
    "2. Oversample the minor class (i.e., randomly duplicate examples)\n",
    "3. Undersample the major class (i.e., randomly delete examples)\n",
    "4. Use several metrics (e.g., Accuracy, Precision, Recall, AUC)\n",
    "\n",
    "Use StratifiedShuffleSplit. This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.\n",
    "\n",
    "Note: like the ShuffleSplit strategy, stratified random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a986abb-2a63-4ae7-9333-7a4cfe292b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard train & test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d2ff9b-1d55-4179-baef-ec46a29497fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the a Stratified K-fold Shuffle Splitter\n",
    "stratified_kfold = StratifiedShuffleSplit(n_splits=10,\n",
    "                                          test_size=.3, \n",
    "                                          random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f892767-69de-442b-bcb5-1be134ee12b9",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a14a67-8eba-41dd-9c58-4ac2dd190bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Features\n",
    "numerical_features = ['Year_Birth', \n",
    "                      'Income', \n",
    "                      'Recency', \n",
    "                      'MntWines', \n",
    "                      'MntFruits', \n",
    "                      'MntMeatProducts', \n",
    "                      'MntFishProducts', \n",
    "                      'MntSweetProducts', \n",
    "                      'MntGoldProds', \n",
    "                      'NumDealsPurchases', \n",
    "                      'NumWebPurchases', \n",
    "                      'NumCatalogPurchases', \n",
    "                      'NumStorePurchases', \n",
    "                      'NumWebVisitsMonth']\n",
    "\n",
    "# Categorical Text Features\n",
    "categorical_text_features = ['Education', \n",
    "                             'Marital_Status']\n",
    "\n",
    "# Categorical Numerical Features\n",
    "categorical_numerical_features = ['Kidhome', \n",
    "                                  'Teenhome', \n",
    "                                  'AcceptedCmp1', \n",
    "                                  'AcceptedCmp2', \n",
    "                                  'AcceptedCmp3', \n",
    "                                  'AcceptedCmp4', \n",
    "                                  'AcceptedCmp5', \n",
    "                                  'Complain', \n",
    "                                  'Dt_Customer_month', \n",
    "                                  'Dt_Customer_dayofweek']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03838419-b05d-4243-be09-3aa6582a269b",
   "metadata": {},
   "source": [
    "## Data Standardization\n",
    "\n",
    "Transform the individual features to look more or less like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "\n",
    "Keep in mind that tree-based methods are scale-invariant, so data standardization is not required.\n",
    "\n",
    "Standardization has to go after training-test split. That's because, standardizing the whole dataset and then split, would introduce into the training set some information about the mean and std of the test set. Remember to standardize the test set with the same scaler trained on the training set. This would be addressed by constructing a pipeline with the scaler as a step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a81e3ad1-409c-44d1-892b-b8a02761ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ColumnTransformer\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('numerical', StandardScaler(), numerical_features),\n",
    "    ('categorical_text', OneHotEncoder(), categorical_text_features),\n",
    "    ('categorical_numerical', 'passthrough', categorical_numerical_features)\n",
    "], verbose_feature_names_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2436ba73-ed02-4d14-a0ee-176c21df6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the ColumnTransformer\n",
    "_ = column_transformer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d2627fd-62f7-4eb0-8b1a-138c454cafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the columns\n",
    "X_train_transformed = pd.DataFrame(column_transformer.transform(X_train), columns=column_transformer.get_feature_names_out())\n",
    "X_test_transformed = pd.DataFrame(column_transformer.transform(X_test), columns=column_transformer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde34e9-b215-44fe-be01-b8d6a82fd2d0",
   "metadata": {},
   "source": [
    "# Models Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11486f6f-b209-440b-bfef-7105de231729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary of model performance\n",
    "performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15567a9-a6c1-416e-b76f-1e54dcb60d31",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "First benchmark model. Use standard train & test split and fit the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e034d5af-cc3d-47ee-b360-b6eea8947347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Train the model\n",
    "model_lr.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions_lr = model_lr.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c6b993-199a-4c28-8686-219126c8c859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 90.12%\n",
      "Model precision: 53.85%\n",
      "Model recall: 26.92%\n",
      "Model f1 score: 35.9%\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "accuracy_lr = round(accuracy_score(y_test, predictions_lr) * 100, 2)\n",
    "precision_lr = round(precision_score(y_test, predictions_lr) * 100, 2)\n",
    "recall_lr = round(recall_score(y_test, predictions_lr) * 100, 2)\n",
    "f1_lr = round(f1_score(y_test, predictions_lr) * 100, 2)\n",
    "\n",
    "print('Model accuracy: {}%'.format(accuracy_lr))\n",
    "print('Model precision: {}%'.format(precision_lr))\n",
    "print('Model recall: {}%'.format(recall_lr))\n",
    "print('Model f1 score: {}%'.format(f1_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7198df42-8b33-43c8-8555-118df8e148da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' dictionary\n",
    "performance['logistic_regression'] = {\n",
    "    'accuracy': 0,\n",
    "    'precision': 0,\n",
    "    'recall': 0,\n",
    "    'f1': 0\n",
    "}\n",
    "performance['logistic_regression']['accuracy'] = accuracy_lr\n",
    "performance['logistic_regression']['precision'] = precision_lr\n",
    "performance['logistic_regression']['recall'] = recall_lr\n",
    "performance['logistic_regression']['f1'] = f1_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cd5fa-ce62-44ea-b455-0be54e92257d",
   "metadata": {},
   "source": [
    "## Logistic Regression - Pipeline\n",
    "\n",
    "Use the same model as before, but within a pipeline (experimental purposes only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "291c8545-928a-4bb1-a6d3-906512cd1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_lr_pipe = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Define the pipeline\n",
    "lr_pipe = Pipeline([\n",
    "    ('feature_transformation', column_transformer),\n",
    "    ('logistic_regression', model_lr_pipe)\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions_lr_pipe = lr_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ace32f8-b1d1-4b88-9087-4631b94f6c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 90.12%\n",
      "Model precision: 53.85%\n",
      "Model recall: 26.92%\n",
      "Model f1 score: 35.9%\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "accuracy_lr_pipe = round(accuracy_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "precision_lr_pipe = round(precision_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "recall_lr_pipe = round(recall_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "f1_lr_pipe = round(f1_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "\n",
    "print('Model accuracy: {}%'.format(accuracy_lr_pipe))\n",
    "print('Model precision: {}%'.format(precision_lr_pipe))\n",
    "print('Model recall: {}%'.format(recall_lr_pipe))\n",
    "print('Model f1 score: {}%'.format(f1_lr_pipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd09d059-9c0e-4a2f-9009-2c1efc11f8a3",
   "metadata": {},
   "source": [
    "As expected, the results are exactly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545d4e2-d60c-426e-a2b0-1546673b1829",
   "metadata": {},
   "source": [
    "## Logistic Regression - Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fd385c2-c6d1-4758-99dc-11b815e457f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 949 1057  769  640  771 1082  895  430 1361 1369  360  152 1479  725\n",
      "  272 1466  478  376 1289  737  747 1469 1354  898 1331  604  525  860\n",
      " 1390 1192  417  715  500 1295  710 1467  464  409 1278  894   71  707\n",
      "  182  522  507  891  141 1400   31 1205   40 1310  107  474 1345  611\n",
      " 1125  749 1001  162  655  864  239 1326 1231  287  196  896  929  350\n",
      " 1363  306  450  499  983  235 1275 1046  608  264  330  907  954  228\n",
      "  218 1255 1411 1282   95  230 1102  967    8   94 1532   42  700  475\n",
      "  179 1305 1081  113 1019 1027 1494 1482  562  912 1300  396  774 1269\n",
      "  331 1508  120 1294  664 1394  365 1481  523 1279   82 1218  616  200\n",
      " 1432  856  717 1055   26  669 1258  679  312 1174  468  797  164  163\n",
      " 1157 1427 1443  568 1029  597  153  494  413 1121  372 1044  813  429\n",
      "  773 1177 1338 1058   28   49  324 1351  177  905 1396 1509 1194  545\n",
      "  332 1313  936  253  509  245 1226 1491  441  188  462 1434  845 1397\n",
      "  830 1409  343  259 1493 1442 1028  126    3  425  506  925 1239  144\n",
      " 1292 1123  567  849 1048  233 1191  930 1200 1225  885 1261  702 1372\n",
      "  319  665  673   78  838  780  630  316 1050 1053  516 1160  979 1422\n",
      " 1307  935  408 1431  928  394  112  209 1083  194 1497  910  985  484\n",
      "  373  410  869 1348  569  814  416 1245  145 1006 1349  754  777 1140\n",
      "  612 1092  380 1324 1438 1249 1341  783  620 1435 1162  323 1124 1182\n",
      "   36 1511  560  155  443  918  788  888  647  666  731 1350  399  322\n",
      " 1237 1385 1138 1071  863 1010  479  661 1527  901   37 1189 1155  150\n",
      "  809  657  873  318  852  991  948  937  502  181  146  793  806  607\n",
      "  818  672  501  129  986  104  878  959  452  592 1074 1260 1062  836\n",
      "   45 1224  137   27  536 1126  297  291   75  862 1105   98 1315  982\n",
      " 1388   65  186  691  189  636   99  621 1381  544  623  263 1060  953\n",
      "  281  837  250  803 1373   81   47  678  994  135  125  584  165  106\n",
      " 1017  792  659  626 1240  309  587 1164 1197  696  899  831  307   29\n",
      " 1520 1340  650  685 1087  890  555  222  167  719  962  224  326  573\n",
      " 1016 1366  944 1035 1032   13  811  279 1133  799   67  617 1449 1320\n",
      "  868  305 1025  973  386  847 1347 1410 1485  968 1212  759  220 1034\n",
      "  987 1215  938 1252 1146  892  288 1290 1425  378 1314  943  377  170\n",
      "  313 1008 1112  257 1193  722  340 1395 1153  603 1309  594  697 1150\n",
      "  359 1459  521 1280  879  945 1454 1480 1043 1104 1462  251]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/pandas/core/indexing.py:1530\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1532\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/pandas/core/series.py:907\u001b[0m, in \u001b[0;36mSeries._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/pandas/core/series.py:892\u001b[0m, in \u001b[0;36mSeries.take\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m indices \u001b[38;5;241m=\u001b[39m ensure_platform_int(indices)\n\u001b[0;32m--> 892\u001b[0m new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\u001b[38;5;241m.\u001b[39mtake(indices)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/pandas/core/indexes/base.py:961\u001b[0m, in \u001b[0;36mIndex.take\u001b[0;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;66;03m# Note: we discard fill_value and use self._na_value, only relevant\u001b[39;00m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;66;03m#  in the case where allow_fill is True and fill_value is not None\u001b[39;00m\n\u001b[0;32m--> 961\u001b[0m taken \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_na_value\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_simple_new(taken, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/pandas/core/algorithms.py:1516\u001b[0m, in \u001b[0;36mtake\u001b[0;34m(arr, indices, axis, allow_fill, fill_value)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1515\u001b[0m     \u001b[38;5;66;03m# NumPy style\u001b[39;00m\n\u001b[0;32m-> 1516\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mIndexError\u001b[0m: index 949 is out of bounds for axis 0 with size 506",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m pipeline_lr_cv \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m      9\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_transformation\u001b[39m\u001b[38;5;124m'\u001b[39m, column_transformer),\n\u001b[1;32m     10\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic_regression\u001b[39m\u001b[38;5;124m'\u001b[39m, model_lr_cv)\n\u001b[1;32m     11\u001b[0m ])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_index)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43my_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/pandas/core/indexing.py:931\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    928\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    930\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 931\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/pandas/core/indexing.py:1557\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1561\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uc2_mobility/lib/python3.8/site-packages/pandas/core/indexing.py:1533\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1532\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message\u001b[39;00m\n\u001b[0;32m-> 1533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model_lr_cv = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Train the model with K-fold\n",
    "for train_index, test_index in stratified_kfold.split(X, y):\n",
    "    \n",
    "    # Define the pipeline\n",
    "    pipeline_lr_cv = Pipeline([\n",
    "        ('feature_transformation', column_transformer),\n",
    "        ('logistic_regression', model_lr_cv)\n",
    "    ])\n",
    "    \n",
    "    print(test_index)\n",
    "    print(y_test.iloc[test_index])\n",
    "    \n",
    "    break\n",
    "        \n",
    "    # Train the model\n",
    "    pipeline_lr_cv.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "\n",
    "    # Get predicitons\n",
    "    predictions_lr_cv = pipeline_lr_cv.predict(X.iloc[test_index])\n",
    "\n",
    "    # Model evaluation\n",
    "    accuracy_lr_cv = round(accuracy_score(y_test.iloc[test_index], predictions_lr_cv) * 100, 2)\n",
    "    precision_lr_cv = round(precision_score(y_test.iloc[test_index], predictions_lr_cv) * 100, 2)\n",
    "    recall_lr_cv = round(recall_score(y_test.iloc[test_index], predictions_lr_cv) * 100, 2)\n",
    "    f1_lr_cv = round(f1_score(y_test.iloc[test_index], predictions_lr_cv) * 100, 2)\n",
    "\n",
    "    print('Model accuracy: {}%'.format(accuracy_lr_cv))\n",
    "    print('Model precision: {}%'.format(precision_lr_cv))\n",
    "    print('Model recall: {}%'.format(recall_lr_cv))\n",
    "    print('Model f1 score: {}%'.format(f1_lr_cv))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445728ea-04ad-4ef7-bd62-8a76cc61c5de",
   "metadata": {},
   "source": [
    "## Bayesian Optimization with HYPEROPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72b12e-627c-47b6-96c2-e1fa1531f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Hyperparamters space for Hyperopt\n",
    "hyperopt_parameters_space = {\n",
    "    'max_depth': hp.quniform(\"max_depth\", 3, 40, 2),\n",
    "    'gamma': hp.uniform ('gamma', 1, 15),\n",
    "    'reg_alpha' : hp.quniform('reg_alpha', 40, 180, 1),\n",
    "    'reg_lambda' : hp.uniform('reg_lambda', 0, 1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 0, 60, 3),\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 3000, 10),\n",
    "    'seed': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926bca8-b0c3-4136-b7cf-55165266d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Objective Function\n",
    "def objective(space, column_transformer=column_transformer, cv=stratified_kfold, X=X, y=y, scoring='roc_auc'):\n",
    "    \n",
    "    # Create the estimator\n",
    "    clf=xgb.XGBClassifier(objective='binary:logistic',\n",
    "                          eval_metric='auc',\n",
    "                          n_estimators=int(space['n_estimators']), \n",
    "                          max_depth=int(space['max_depth']), \n",
    "                          gamma=space['gamma'],\n",
    "                          reg_alpha=int(space['reg_alpha']),\n",
    "                          min_child_weight=int(space['min_child_weight']),\n",
    "                          colsample_bytree=int(space['colsample_bytree']),\n",
    "                          use_label_encoder=False)\n",
    "    \n",
    "    # Define the Pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('feature_transformation', column_transformer), \n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    # Init accuracy and precision list for K-fold\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    \n",
    "    # Train the model with K-fold\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "    \n",
    "        # Train the model\n",
    "        pipeline.fit(X[train_index], y[train_index])\n",
    "\n",
    "        # Get predicitons\n",
    "        predictions = pipeline.predict(X[test_index])\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy.append(accuracy_score(y[test_index], predictions))\n",
    "        \n",
    "        # Calculate precision\n",
    "        precision.append(precision_score(y[test_index], predictions))\n",
    "                                  \n",
    "        \n",
    "    # Calculate the score\n",
    "    cv_score = cross_val_score(pipeline, X, y, cv=cv, scoring=scoring, n_jobs=1).mean()\n",
    "    accuracy_mean = accuracy.mean()\n",
    "    precision_score = precision.mean()\n",
    "    \n",
    "    print(cv_score)\n",
    "    print(accuracy_mean)\n",
    "    print(precision_score)\n",
    "                \n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f90003-c31f-4e11-a5f0-3c0fb4e209ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = fmin(fn=objective,\n",
    "                  space=hyperopt_parameters_space,\n",
    "                  algo=tpe.suggest,\n",
    "                  max_evals=50,\n",
    "                  trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a7c5d7-ab43-42f1-a048-c2da36494240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
