{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a8425c-154a-42b2-8e92-2b6c68dfcaba",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The notebook is intended to perform a binary classification over the 'Response' label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f217cfae-abee-40ce-8e84-33c6ffc96f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Modules\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set Pandas Options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d96ec02-b877-4a3e-9d14-b034a624dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook configurations\n",
    "scaler_type = 'StandardScaler' # Options: StandardScaler\n",
    "model_type = 'XGBoost' # Options: XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97637c10-2df0-42a5-b62d-e44b32f0cc2e",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722fbeee-0d35-456e-b2eb-1ca975bf123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = pd.read_csv('./../data/marketing_campaign_prepared.csv', encoding='latin1', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68295105-c936-4969-8a68-312d8c27d2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1533 entries, 0 to 1532\n",
      "Data columns (total 28 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   ID                     1533 non-null   int64  \n",
      " 1   Year_Birth             1533 non-null   int64  \n",
      " 2   Education              1533 non-null   object \n",
      " 3   Marital_Status         1533 non-null   object \n",
      " 4   Income                 1533 non-null   float64\n",
      " 5   Kidhome                1533 non-null   int64  \n",
      " 6   Teenhome               1533 non-null   int64  \n",
      " 7   Recency                1533 non-null   int64  \n",
      " 8   MntWines               1533 non-null   int64  \n",
      " 9   MntFruits              1533 non-null   int64  \n",
      " 10  MntMeatProducts        1533 non-null   int64  \n",
      " 11  MntFishProducts        1533 non-null   int64  \n",
      " 12  MntSweetProducts       1533 non-null   int64  \n",
      " 13  MntGoldProds           1533 non-null   int64  \n",
      " 14  NumDealsPurchases      1533 non-null   int64  \n",
      " 15  NumWebPurchases        1533 non-null   int64  \n",
      " 16  NumCatalogPurchases    1533 non-null   int64  \n",
      " 17  NumStorePurchases      1533 non-null   int64  \n",
      " 18  NumWebVisitsMonth      1533 non-null   int64  \n",
      " 19  AcceptedCmp3           1533 non-null   int64  \n",
      " 20  AcceptedCmp4           1533 non-null   int64  \n",
      " 21  AcceptedCmp5           1533 non-null   int64  \n",
      " 22  AcceptedCmp1           1533 non-null   int64  \n",
      " 23  AcceptedCmp2           1533 non-null   int64  \n",
      " 24  Complain               1533 non-null   int64  \n",
      " 25  Response               1533 non-null   int64  \n",
      " 26  Dt_Customer_month      1533 non-null   int64  \n",
      " 27  Dt_Customer_dayofweek  1533 non-null   int64  \n",
      "dtypes: float64(1), int64(25), object(2)\n",
      "memory usage: 335.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57b099-f6af-48e5-bd73-cde46dfe71a1",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4c6ac-994e-4b64-a414-616b0203e158",
   "metadata": {},
   "source": [
    "## Features & Label Definition\n",
    "\n",
    "The 'ID' column does not bring any useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd5e56e-960b-4a19-b6fc-703308de3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x and y\n",
    "X = data.drop(['ID', 'Response'], axis=1)\n",
    "y = data['Response']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b089fd86-88fc-4206-a612-788601a7a8fe",
   "metadata": {},
   "source": [
    "## Train & Test Split\n",
    "\n",
    "Since the label is characterized by a strong imbalancing in the class distribution, we need to address it carefully:\n",
    "1. Ensure that the training and test sets have the same proportions of the two classes\n",
    "2. Oversample the minor class (i.e., randomly duplicate examples)\n",
    "3. Undersample the major class (i.e., randomly delete examples)\n",
    "4. Use several metrics (e.g., Accuracy, Precision, Recall, AUC)\n",
    "\n",
    "Use StratifiedShuffleSplit. This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.\n",
    "\n",
    "Note: like the ShuffleSplit strategy, stratified random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24d2ff9b-1d55-4179-baef-ec46a29497fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Splitter\n",
    "stratified_kfold = StratifiedShuffleSplit(n_splits=10,\n",
    "                                          test_size=.3, \n",
    "                                          random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f892767-69de-442b-bcb5-1be134ee12b9",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84a14a67-8eba-41dd-9c58-4ac2dd190bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Features\n",
    "numerical_features = ['Year_Birth', \n",
    "                      'Income', \n",
    "                      'Recency', \n",
    "                      'MntWines', \n",
    "                      'MntFruits', \n",
    "                      'MntMeatProducts', \n",
    "                      'MntFishProducts', \n",
    "                      'MntSweetProducts', \n",
    "                      'MntGoldProds', \n",
    "                      'NumDealsPurchases', \n",
    "                      'NumWebPurchases', \n",
    "                      'NumCatalogPurchases', \n",
    "                      'NumStorePurchases', \n",
    "                      'NumWebVisitsMonth']\n",
    "\n",
    "# Categorical Text Features\n",
    "categorical_text_features = ['Education', \n",
    "                             'Marital_Status']\n",
    "\n",
    "# Categorical Numerical Features\n",
    "categorical_numerical_features = ['Kidhome', \n",
    "                                  'Teenhome', \n",
    "                                  'AcceptedCmp1', \n",
    "                                  'AcceptedCmp2', \n",
    "                                  'AcceptedCmp3', \n",
    "                                  'AcceptedCmp4', \n",
    "                                  'AcceptedCmp5', \n",
    "                                  'Complain', \n",
    "                                  'Dt_Customer_month', \n",
    "                                  'Dt_Customer_dayofweek']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03838419-b05d-4243-be09-3aa6582a269b",
   "metadata": {},
   "source": [
    "## Data Standardization\n",
    "\n",
    "Transform the individual features to look more or less like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "\n",
    "Keep in mind that tree-based methods are scale-invariant, so data standardization is not required.\n",
    "\n",
    "Standardization has to go after training-test split. That's because, standardizing the whole dataset and then split, would introduce into the training set some information about the mean and std of the test set. Remember to standardize the test set with the same scaler trained on the training set. This would be addressed by constructing a pipeline with the scaler as a step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a81e3ad1-409c-44d1-892b-b8a02761ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ColumnTransformer\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('numerical_transformation', StandardScaler(), numerical_features),\n",
    "    ('categorical_text_transformation', OrdinalEncoder(), categorical_text_features),\n",
    "    ('categorical_numerical_transformation', 'passthrough', categorical_numerical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde34e9-b215-44fe-be01-b8d6a82fd2d0",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445728ea-04ad-4ef7-bd62-8a76cc61c5de",
   "metadata": {},
   "source": [
    "## Bayesian Optimization with HYPEROPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df72b12e-627c-47b6-96c2-e1fa1531f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Hyperparamters space for Hyperopt\n",
    "hyperopt_parameters_space = {\n",
    "    'max_depth': hp.quniform(\"max_depth\", 3, 40, 2),\n",
    "    'gamma': hp.uniform ('gamma', 1, 15),\n",
    "    'reg_alpha' : hp.quniform('reg_alpha', 40, 180, 1),\n",
    "    'reg_lambda' : hp.uniform('reg_lambda', 0, 1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 0, 60, 3),\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 3000, 10),\n",
    "    'seed': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4926bca8-b0c3-4136-b7cf-55165266d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Objective Function\n",
    "def objective(space, column_transformer=column_transformer, cv=stratified_kfold, X=X, y=y, scoring='roc_auc'):\n",
    "    \n",
    "    # Create the estimator\n",
    "    clf=xgb.XGBClassifier(objective='binary:logistic',\n",
    "                          eval_metric='auc',\n",
    "                          n_estimators=int(space['n_estimators']), \n",
    "                          max_depth=int(space['max_depth']), \n",
    "                          gamma=space['gamma'],\n",
    "                          reg_alpha=int(space['reg_alpha']),\n",
    "                          min_child_weight=int(space['min_child_weight']),\n",
    "                          colsample_bytree=int(space['colsample_bytree']),\n",
    "                          use_label_encoder=False)\n",
    "    \n",
    "    # Define the Pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('feature_transformation', column_transformer), \n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X, y)\n",
    "        \n",
    "    # Calculate the score\n",
    "    score = cross_val_score(pipeline, X, y, cv=cv, scoring=scoring, n_jobs=1).mean()\n",
    "    \n",
    "    print(score)\n",
    "                \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f90003-c31f-4e11-a5f0-3c0fb4e209ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "parameters = fmin(fn=objective,\n",
    "                  space=hyperopt_parameters_space,\n",
    "                  algo=tpe.suggest,\n",
    "                  max_evals=50,\n",
    "                  trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a7c5d7-ab43-42f1-a048-c2da36494240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
