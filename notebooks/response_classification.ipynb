{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a8425c-154a-42b2-8e92-2b6c68dfcaba",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The notebook is intended to perform a binary classification over the 'Response' label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f217cfae-abee-40ce-8e84-33c6ffc96f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, roc_auc_score, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as ex\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# Set Pandas Options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Configure MLFlow Tracking Server\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97637c10-2df0-42a5-b62d-e44b32f0cc2e",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "722fbeee-0d35-456e-b2eb-1ca975bf123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = pd.read_csv('./../data/marketing_campaign_prepared.csv', encoding='latin1', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57b099-f6af-48e5-bd73-cde46dfe71a1",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4c6ac-994e-4b64-a414-616b0203e158",
   "metadata": {},
   "source": [
    "## Features & Label Definition\n",
    "\n",
    "The 'ID' column does not bring any useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd5e56e-960b-4a19-b6fc-703308de3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x and y\n",
    "X = data.drop(['ID', 'Response'], axis=1)\n",
    "y = data['Response']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b089fd86-88fc-4206-a612-788601a7a8fe",
   "metadata": {},
   "source": [
    "## Train & Test Split\n",
    "\n",
    "Since the label is characterized by a strong imbalancing in the class distribution, we need to address it carefully:\n",
    "1. Ensure that the training and test sets have the same proportions of the two classes\n",
    "2. Oversample the minor class (i.e., randomly duplicate examples)\n",
    "3. Undersample the major class (i.e., randomly delete examples)\n",
    "4. Use several metrics (e.g., Accuracy, Precision, Recall, AUC)\n",
    "\n",
    "Use StratifiedShuffleSplit. This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.\n",
    "\n",
    "Note: like the ShuffleSplit strategy, stratified random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a986abb-2a63-4ae7-9333-7a4cfe292b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard train & test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d2ff9b-1d55-4179-baef-ec46a29497fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the a Stratified K-fold Shuffle Splitter\n",
    "stratified_kfold = StratifiedShuffleSplit(n_splits=10,\n",
    "                                          test_size=.3, \n",
    "                                          random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f892767-69de-442b-bcb5-1be134ee12b9",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a14a67-8eba-41dd-9c58-4ac2dd190bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Features\n",
    "numerical_features = ['Year_Birth', \n",
    "                      'Income', \n",
    "                      'Recency', \n",
    "                      'MntWines', \n",
    "                      'MntFruits', \n",
    "                      'MntMeatProducts', \n",
    "                      'MntFishProducts', \n",
    "                      'MntSweetProducts', \n",
    "                      'MntGoldProds', \n",
    "                      'NumDealsPurchases', \n",
    "                      'NumWebPurchases', \n",
    "                      'NumCatalogPurchases', \n",
    "                      'NumStorePurchases', \n",
    "                      'NumWebVisitsMonth']\n",
    "\n",
    "# Categorical Text Features\n",
    "categorical_text_features = ['Education', \n",
    "                             'Marital_Status']\n",
    "\n",
    "# Categorical Numerical Features\n",
    "categorical_numerical_features = ['Kidhome', \n",
    "                                  'Teenhome', \n",
    "                                  'AcceptedCmp1', \n",
    "                                  'AcceptedCmp2', \n",
    "                                  'AcceptedCmp3', \n",
    "                                  'AcceptedCmp4', \n",
    "                                  'AcceptedCmp5', \n",
    "                                  'Complain', \n",
    "                                  'Dt_Customer_month', \n",
    "                                  'Dt_Customer_dayofweek']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03838419-b05d-4243-be09-3aa6582a269b",
   "metadata": {},
   "source": [
    "## Data Standardization\n",
    "\n",
    "Transform the individual features to look more or less like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "\n",
    "Keep in mind that tree-based methods are scale-invariant, so data standardization is not required.\n",
    "\n",
    "Standardization has to go after training-test split. That's because, standardizing the whole dataset and then split, would introduce into the training set some information about the mean and std of the test set. Remember to standardize the test set with the same scaler trained on the training set. This would be addressed by constructing a pipeline with the scaler as a step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a81e3ad1-409c-44d1-892b-b8a02761ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ColumnTransformer\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('numerical', StandardScaler(), numerical_features),\n",
    "    ('categorical_text', OneHotEncoder(), categorical_text_features),\n",
    "    ('categorical_numerical', 'passthrough', categorical_numerical_features)\n",
    "], verbose_feature_names_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2436ba73-ed02-4d14-a0ee-176c21df6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the ColumnTransformer\n",
    "_ = column_transformer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d2627fd-62f7-4eb0-8b1a-138c454cafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the columns\n",
    "X_train_transformed = pd.DataFrame(column_transformer.transform(X_train), columns=column_transformer.get_feature_names_out())\n",
    "X_test_transformed = pd.DataFrame(column_transformer.transform(X_test), columns=column_transformer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde34e9-b215-44fe-be01-b8d6a82fd2d0",
   "metadata": {},
   "source": [
    "# Models Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d816ea7-e83d-49db-acc0-b7b306114fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the used metrics\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'cv_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11486f6f-b209-440b-bfef-7105de231729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrame of model performance\n",
    "performance = pd.DataFrame(columns=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15567a9-a6c1-416e-b76f-1e54dcb60d31",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "First benchmark model. Use standard train & test split and fit the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e034d5af-cc3d-47ee-b360-b6eea8947347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Train the model\n",
    "model_lr.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions_lr = model_lr.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5c6b993-199a-4c28-8686-219126c8c859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 90.12%\n",
      "Model precision: 53.85%\n",
      "Model recall: 26.92%\n",
      "Model f1 score: 35.9%\n",
      "Model ROC AUC: 62.14%\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "accuracy_lr = round(accuracy_score(y_test, predictions_lr) * 100, 2)\n",
    "precision_lr = round(precision_score(y_test, predictions_lr) * 100, 2)\n",
    "recall_lr = round(recall_score(y_test, predictions_lr) * 100, 2)\n",
    "f1_lr = round(f1_score(y_test, predictions_lr) * 100, 2)\n",
    "roc_auc_lr = round(roc_auc_score(y_test, predictions_lr) * 100, 2)\n",
    "\n",
    "print('Model accuracy: {}%'.format(accuracy_lr))\n",
    "print('Model precision: {}%'.format(precision_lr))\n",
    "print('Model recall: {}%'.format(recall_lr))\n",
    "print('Model f1 score: {}%'.format(f1_lr))\n",
    "print('Model ROC AUC: {}%'.format(roc_auc_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cd5fa-ce62-44ea-b455-0be54e92257d",
   "metadata": {},
   "source": [
    "## Logistic Regression - Pipeline\n",
    "\n",
    "Use the same model as before, but within a pipeline (experimental purposes only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c9d675d-2d5a-4357-9936-bc92a2a1b23a",
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "API request to endpoint /api/2.0/mlflow/experiments/list failed with error code 403 != 200. Response body: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/share/virtualenvs/customer_personality-ilk9eoE_/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:285\u001b[0m, in \u001b[0;36mRestStore.get_experiment_by_name\u001b[0;34m(self, experiment_name)\u001b[0m\n\u001b[1;32m    284\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(GetExperimentByName(experiment_name\u001b[38;5;241m=\u001b[39mexperiment_name))\n\u001b[0;32m--> 285\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGetExperimentByName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Experiment\u001b[38;5;241m.\u001b[39mfrom_proto(response_proto\u001b[38;5;241m.\u001b[39mexperiment)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/customer_personality-ilk9eoE_/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:56\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     55\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/customer_personality-ilk9eoE_/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:256\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto)\u001b[0m\n\u001b[1;32m    253\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\n\u001b[1;32m    254\u001b[0m         host_creds\u001b[38;5;241m=\u001b[39mhost_creds, endpoint\u001b[38;5;241m=\u001b[39mendpoint, method\u001b[38;5;241m=\u001b[39mmethod, json\u001b[38;5;241m=\u001b[39mjson_body\n\u001b[1;32m    255\u001b[0m     )\n\u001b[0;32m--> 256\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/customer_personality-ilk9eoE_/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:191\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    187\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m failed with error code \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    188\u001b[0m             endpoint,\n\u001b[1;32m    189\u001b[0m             response\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    190\u001b[0m         )\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Response body: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (base_msg, response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Skip validation for endpoints (e.g. DBFS file-download API) which may return a non-JSON\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# response\u001b[39;00m\n",
      "\u001b[0;31mMlflowException\u001b[0m: API request to endpoint /api/2.0/mlflow/experiments/get-by-name failed with error code 403 != 200. Response body: ''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m experiment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Retrieve MLFlow Experiment\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m experiment \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Checking if Experiment exists\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/customer_personality-ilk9eoE_/lib/python3.10/site-packages/mlflow/tracking/fluent.py:1020\u001b[0m, in \u001b[0;36mget_experiment_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_experiment_by_name\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Experiment]:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;124;03m    Retrieve an experiment by experiment name from the backend store\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m        Lifecycle_stage: active\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/customer_personality-ilk9eoE_/lib/python3.10/site-packages/mlflow/tracking/client.py:462\u001b[0m, in \u001b[0;36mMlflowClient.get_experiment_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Experiment]:\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m    Retrieve an experiment by experiment name from the backend store\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m        Lifecycle_stage: active\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/customer_personality-ilk9eoE_/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:170\u001b[0m, in \u001b[0;36mTrackingServiceClient.get_experiment_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    :param name: The experiment name.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    :return: :py:class:`mlflow.entities.Experiment`\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/customer_personality-ilk9eoE_/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:297\u001b[0m, in \u001b[0;36mRestStore.get_experiment_by_name\u001b[0;34m(self, experiment_name)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# Fall back to using ListExperiments-based implementation.\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m experiment \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mViewType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m experiment\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m experiment_name:\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m experiment\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/customer_personality-ilk9eoE_/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:77\u001b[0m, in \u001b[0;36mRestStore.list_experiments\u001b[0;34m(self, view_type, max_results, page_token)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m:param view_type: Qualify requested type of experiments.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m:param max_results: If passed, specifies the maximum number of experiments desired. If not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m         for the next page can be obtained via the ``token`` attribute of the object.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[1;32m     75\u001b[0m     ListExperiments(view_type\u001b[38;5;241m=\u001b[39mview_type, max_results\u001b[38;5;241m=\u001b[39mmax_results, page_token\u001b[38;5;241m=\u001b[39mpage_token)\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mListExperiments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m experiments \u001b[38;5;241m=\u001b[39m [Experiment\u001b[38;5;241m.\u001b[39mfrom_proto(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m response_proto\u001b[38;5;241m.\u001b[39mexperiments]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# If the response doesn't contain `next_page_token`, `response_proto.next_page_token`\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# returns an empty string (default value for a string proto field).\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/customer_personality-ilk9eoE_/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:56\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     54\u001b[0m endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m     55\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/customer_personality-ilk9eoE_/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:256\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\n\u001b[1;32m    254\u001b[0m         host_creds\u001b[38;5;241m=\u001b[39mhost_creds, endpoint\u001b[38;5;241m=\u001b[39mendpoint, method\u001b[38;5;241m=\u001b[39mmethod, json\u001b[38;5;241m=\u001b[39mjson_body\n\u001b[1;32m    255\u001b[0m     )\n\u001b[0;32m--> 256\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    258\u001b[0m parse_dict(js_dict\u001b[38;5;241m=\u001b[39mjs_dict, message\u001b[38;5;241m=\u001b[39mresponse_proto)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/customer_personality-ilk9eoE_/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:191\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m failed with error code \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    188\u001b[0m             endpoint,\n\u001b[1;32m    189\u001b[0m             response\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    190\u001b[0m         )\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Response body: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (base_msg, response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Skip validation for endpoints (e.g. DBFS file-download API) which may return a non-JSON\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# response\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endpoint\u001b[38;5;241m.\u001b[39mstartswith(_REST_API_PATH_PREFIX) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n",
      "\u001b[0;31mMlflowException\u001b[0m: API request to endpoint /api/2.0/mlflow/experiments/list failed with error code 403 != 200. Response body: ''"
     ]
    }
   ],
   "source": [
    "# Experiment name\n",
    "experiment_name = 'Logistic Regression'\n",
    "\n",
    "# Retrieve MLFlow Experiment\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "# Checking if Experiment exists\n",
    "if experiment is None:\n",
    "    \n",
    "    print('Creating MLFlow experiment')\n",
    "\n",
    "    # Create experiment\n",
    "    _ = mlflow.create_experiment(experiment_name)\n",
    "\n",
    "    # Retrieve experiment\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    \n",
    "print('Experiment ID: ' + experiment.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb484214-1f42-481b-812b-503e6cbbfdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's Hyperparameters\n",
    "max_iter = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c8545-928a-4bb1-a6d3-906512cd1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start MLFlow Run\n",
    "with mlflow.start_run(experiment_id=experiment.experiment_id):\n",
    "\n",
    "    # Define the model\n",
    "    model_lr_pipe = LogisticRegression(max_iter=max_iter)\n",
    "\n",
    "    # Define the pipeline\n",
    "    lr_pipe = Pipeline([\n",
    "        ('feature_transformation', column_transformer),\n",
    "        ('logistic_regression', model_lr_pipe)\n",
    "    ])\n",
    "\n",
    "    # Train the pipeline\n",
    "    lr_pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    predictions_lr_pipe = lr_pipe.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy_lr_pipe = round(accuracy_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "    precision_lr_pipe = round(precision_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "    recall_lr_pipe = round(recall_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "    f1_lr_pipe = round(f1_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "    roc_auc_lr_pipe = round(roc_auc_score(y_test, predictions_lr_pipe) * 100, 2)\n",
    "    cv_score_lr_pipe = round(cross_val_score(lr_pipe, X, y, cv=stratified_kfold).mean() * 100, 2)\n",
    "    \n",
    "    print('Model accuracy: {}%'.format(accuracy_lr_pipe))\n",
    "    print('Model precision: {}%'.format(precision_lr_pipe))\n",
    "    print('Model recall: {}%'.format(recall_lr_pipe))\n",
    "    print('Model f1 score: {}%'.format(f1_lr_pipe))\n",
    "    print('Model ROC AUC: {}%'.format(roc_auc_lr_pipe))\n",
    "    print('Model Cross Validation score: {}%'.format(cv_score_lr_pipe))\n",
    "    \n",
    "    # Log MLFlow\n",
    "    mlflow.log_param('max_iter', max_iter)\n",
    "    mlflow.log_metrics({'Accuracy': accuracy_lr_pipe,\n",
    "                        'Precision': precision_lr_pipe,\n",
    "                        'Recall': recall_lr_pipe,\n",
    "                        'F1 Score': f1_lr_pipe,\n",
    "                        'ROC AUC': roc_auc_lr_pipe,\n",
    "                        'CV Score': cv_score_lr_pipe})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ab3c7-4d79-4577-a0d2-5072886b2643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' DataFrame\n",
    "performance.loc['logistic_regression'] = [accuracy_lr_pipe, \n",
    "                                          precision_lr_pipe, \n",
    "                                          recall_lr_pipe, \n",
    "                                          f1_lr_pipe, \n",
    "                                          roc_auc_lr_pipe, \n",
    "                                          cv_score_lr_pipe]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545d4e2-d60c-426e-a2b0-1546673b1829",
   "metadata": {},
   "source": [
    "## Logistic Regression - Cross-Validation training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ea5ed-cee7-4059-9c74-35380b7af018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment name\n",
    "experiment_name = 'Logistic Regression - Cross Validation'\n",
    "\n",
    "# Retrieve MLFlow Experiment\n",
    "experiment = get_experiment_by_name(experiment_name)\n",
    "\n",
    "# Checking if Experiment exists\n",
    "if experiment is None:\n",
    "    \n",
    "    print('Creating MLFlow experiment')\n",
    "\n",
    "    # Create experiment\n",
    "    _ = create_experiment(experiment_name)\n",
    "\n",
    "    # Retrieve experiment\n",
    "    experiment = get_experiment_by_name(experiment_name)\n",
    "    \n",
    "print('Experiment ID: ' + experiment.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd385c2-c6d1-4758-99dc-11b815e457f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_lr_cv = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_lr_cv = Pipeline([\n",
    "    ('feature_transformation', column_transformer),\n",
    "    ('logistic_regression', model_lr_cv)\n",
    "])\n",
    "\n",
    "# Initialize metrics lists\n",
    "accuracy_lr_cv_list = []\n",
    "precision_lr_cv_list = []\n",
    "recall_lr_cv_list = []\n",
    "f1_lr_cv_list = []\n",
    "roc_auc_lr_cv_list = []\n",
    "\n",
    "# Train the model with K-fold\n",
    "for train_index, test_index in stratified_kfold.split(X, y):\n",
    "            \n",
    "    # Train the model\n",
    "    pipeline_lr_cv.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "\n",
    "    # Get predicitons\n",
    "    predictions_lr_cv = pipeline_lr_cv.predict(X.iloc[test_index])\n",
    "\n",
    "    # Model evaluation\n",
    "    accuracy_lr_cv_list.append(round(accuracy_score(y.iloc[test_index], predictions_lr_cv) * 100, 2))\n",
    "    precision_lr_cv_list.append(round(precision_score(y.iloc[test_index], predictions_lr_cv) * 100, 2))\n",
    "    recall_lr_cv_list.append(round(recall_score(y.iloc[test_index], predictions_lr_cv) * 100, 2))\n",
    "    f1_lr_cv_list.append(round(f1_score(y.iloc[test_index], predictions_lr_cv) * 100, 2))\n",
    "    roc_auc_lr_cv_list.append(round(roc_auc_score(y.iloc[test_index], predictions_lr_cv) * 100, 2))\n",
    "    \n",
    "# Compute average of metrics among the K-Folds\n",
    "accuracy_lr_cv = round(np.mean(accuracy_lr_cv_list), 2)\n",
    "precision_lr_cv = round(np.mean(precision_lr_cv_list), 2)\n",
    "recall_lr_cv = round(np.mean(recall_lr_cv_list), 2)\n",
    "f1_lr_cv = round(np.mean(f1_lr_cv_list), 2)\n",
    "roc_auc_lr_cv = round(np.mean(roc_auc_lr_cv_list), 2)\n",
    "cv_score_lr_cv = round(cross_val_score(pipeline_lr_cv, X, y, cv=stratified_kfold).mean() * 100, 2)\n",
    "\n",
    "print('Model accuracy: {}%'.format(accuracy_lr_cv))\n",
    "print('Model precision: {}%'.format(precision_lr_cv))\n",
    "print('Model recall: {}%'.format(recall_lr_cv))\n",
    "print('Model f1 score: {}%'.format(f1_lr_cv))\n",
    "print('Model ROC AUC: {}%'.format(roc_auc_lr_cv))\n",
    "print('Model Cross Validation score: {}%'.format(cv_score_lr_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f639ba0-6906-42fc-8bcf-fdfae5f87745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' DataFrame\n",
    "performance.loc['logistic_regression_cv'] = [accuracy_lr_cv, \n",
    "                                             precision_lr_cv, \n",
    "                                             recall_lr_cv, \n",
    "                                             f1_lr_cv, \n",
    "                                             roc_auc_lr_cv, \n",
    "                                             cv_score_lr_cv]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d85317-00c6-4ed6-9445-035973ec0398",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55be53d-e74a-4032-97a8-c524f7c69d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_xbg_cv = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                                 eval_metric='auc',\n",
    "                                 n_estimators=300,\n",
    "                                 max_depth=8,\n",
    "                                 min_child_weight=5,\n",
    "                                 use_label_encoder=False)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_xgb_cv = Pipeline([\n",
    "    ('feature_transformation', column_transformer),\n",
    "    ('xgboost_classifier', model_xbg_cv)\n",
    "])\n",
    "\n",
    "# Initialize metrics lists\n",
    "accuracy_xgb_cv_list = []\n",
    "precision_xgb_cv_list = []\n",
    "recall_xgb_cv_list = []\n",
    "f1_xgb_cv_list = []\n",
    "roc_auc_xgb_cv_list = []\n",
    "\n",
    "# Train the model with K-fold\n",
    "for train_index, test_index in stratified_kfold.split(X, y):\n",
    "          \n",
    "    # Train the model\n",
    "    pipeline_xgb_cv.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "\n",
    "    # Get predicitons\n",
    "    predictions_xgb_cv = pipeline_xgb_cv.predict(X.iloc[test_index])\n",
    "\n",
    "    # Model evaluation\n",
    "    accuracy_xgb_cv_list.append(round(accuracy_score(y.iloc[test_index], predictions_xgb_cv) * 100, 2))\n",
    "    precision_xgb_cv_list.append(round(precision_score(y.iloc[test_index], predictions_xgb_cv) * 100, 2))\n",
    "    recall_xgb_cv_list.append(round(recall_score(y.iloc[test_index], predictions_xgb_cv) * 100, 2))\n",
    "    f1_xgb_cv_list.append(round(f1_score(y.iloc[test_index], predictions_xgb_cv) * 100, 2))\n",
    "    roc_auc_xgb_cv_list.append(round(roc_auc_score(y.iloc[test_index], predictions_xgb_cv) * 100, 2))\n",
    "    \n",
    "# Compute average of metrics among the K-Folds\n",
    "accuracy_xgb_cv = round(np.mean(accuracy_xgb_cv_list), 2)\n",
    "precision_xgb_cv = round(np.mean(precision_xgb_cv_list), 2)\n",
    "recall_xgb_cv = round(np.mean(recall_xgb_cv_list), 2)\n",
    "f1_xgb_cv = round(np.mean(f1_xgb_cv_list), 2)\n",
    "roc_auc_xgb_cv = round(np.mean(roc_auc_xgb_cv_list), 2)\n",
    "cv_score_xgb_cv = round(cross_val_score(pipeline_xgb_cv, X, y, cv=stratified_kfold).mean() * 100, 2)\n",
    "\n",
    "\n",
    "print('Model accuracy: {}%'.format(accuracy_xgb_cv))\n",
    "print('Model precision: {}%'.format(precision_xgb_cv))\n",
    "print('Model recall: {}%'.format(recall_xgb_cv))\n",
    "print('Model f1 score: {}%'.format(f1_xgb_cv))\n",
    "print('Model ROC AUC: {}%'.format(roc_auc_xgb_cv))\n",
    "print('Model Cross Validation score: {}%'.format(cv_score_xgb_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83461b3b-ad0f-4859-a2c4-8cf2cb1bbd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' DataFrame\n",
    "performance.loc['xgboost_classifier_cv'] = [accuracy_xgb_cv, \n",
    "                                            precision_xgb_cv, \n",
    "                                            recall_xgb_cv, \n",
    "                                            f1_xgb_cv, \n",
    "                                            roc_auc_xgb_cv, \n",
    "                                            cv_score_xgb_cv]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445728ea-04ad-4ef7-bd62-8a76cc61c5de",
   "metadata": {},
   "source": [
    "## XGBoost with HYPEROPT Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72b12e-627c-47b6-96c2-e1fa1531f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Hyperparamters space for Hyperopt\n",
    "hyperopt_parameters_space = {\n",
    "    'max_depth': hp.quniform(\"max_depth\", 3, 40, 2),\n",
    "    'gamma': hp.uniform ('gamma', 0, 1),\n",
    "    #'reg_alpha' : hp.quniform('reg_alpha', 40, 180, 1),\n",
    "    #'reg_lambda' : hp.uniform('reg_lambda', 0, 1),\n",
    "    #'colsample_bytree' : hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 0, 60, 3),\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 3000, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926bca8-b0c3-4136-b7cf-55165266d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Objective Function\n",
    "def objective(space, column_transformer=column_transformer, cv=stratified_kfold, X=X, y=y):\n",
    "    \n",
    "    # Create the estimator\n",
    "    clf=xgb.XGBClassifier(objective='binary:logistic',\n",
    "                          eval_metric='auc',\n",
    "                          n_estimators=int(space['n_estimators']), \n",
    "                          max_depth=int(space['max_depth']), \n",
    "                          gamma=space['gamma'],\n",
    "                          #reg_alpha=int(space['reg_alpha']),\n",
    "                          min_child_weight=int(space['min_child_weight']),\n",
    "                          #colsample_bytree=int(space['colsample_bytree']),\n",
    "                          use_label_encoder=False)\n",
    "    \n",
    "    # Define the Pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('feature_transformation', column_transformer), \n",
    "        ('classifier', clf)\n",
    "    ]) \n",
    "   \n",
    "    # Initialize losses lists\n",
    "    log_loss_list = []\n",
    "    \n",
    "    # Train the model with K-fold\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "    \n",
    "        # Train the model\n",
    "        pipeline.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "\n",
    "        # Get predicitons\n",
    "        predictions = pipeline.predict(X.iloc[test_index])\n",
    "        \n",
    "        # Model loss\n",
    "        log_loss_list.append(round(log_loss(y.iloc[test_index], predictions) * 100, 2))\n",
    "                                          \n",
    "    # Compute average of metrics among the K-Folds\n",
    "    log_loss_score = round(np.mean(log_loss_list), 2)\n",
    "           \n",
    "    return log_loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f90003-c31f-4e11-a5f0-3c0fb4e209ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Hyperparameters Tuning\n",
    "parameters_xgb_cv_hyperopt = fmin(fn=objective,\n",
    "                                  space=hyperopt_parameters_space,\n",
    "                                  algo=tpe.suggest,\n",
    "                                  max_evals=5,\n",
    "                                  trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8086ae-a188-47c9-8624-b54c1f5865b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model_xgb_cv_hyperopt = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                                          eval_metric='auc',\n",
    "                                          n_estimators=int(parameters_xgb_cv_hyperopt['n_estimators']),\n",
    "                                          max_depth=int(parameters_xgb_cv_hyperopt['max_depth']), \n",
    "                                          gamma=parameters_xgb_cv_hyperopt['gamma'],\n",
    "                                          #reg_alpha=int(parameters_xgb_cv_hyperopt['reg_alpha']),\n",
    "                                          min_child_weight=int(parameters_xgb_cv_hyperopt['min_child_weight']),\n",
    "                                          #colsample_bytree=int(parameters_xgb_cv_hyperopt['colsample_bytree']),\n",
    "                                          use_label_encoder=False)\n",
    "# Define the pipeline\n",
    "pipeline_xgb_cv_hyperopt = Pipeline([\n",
    "    ('feature_transformation', column_transformer),\n",
    "    ('xgboost_classifier', model_xgb_cv_hyperopt)\n",
    "])\n",
    "\n",
    "# Initialize metrics lists\n",
    "accuracy_xgb_cv_hyperopt_list = []\n",
    "precision_xgb_cv_hyperopt_list = []\n",
    "recall_xgb_cv_hyperopt_list = []\n",
    "f1_xgb_cv_hyperopt_list = []\n",
    "roc_auc_xgb_cv_hyperopt_list = []\n",
    "\n",
    "# Train the model with K-fold\n",
    "for train_index, test_index in stratified_kfold.split(X, y):\n",
    "        \n",
    "    # Train the model\n",
    "    pipeline_xgb_cv_hyperopt.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "\n",
    "    # Get predicitons\n",
    "    predictions_xgb_cv_hyperopt = pipeline_xgb_cv_hyperopt.predict(X.iloc[test_index])\n",
    "\n",
    "    # Model evaluation\n",
    "    accuracy_xgb_cv_hyperopt_list.append(round(accuracy_score(y.iloc[test_index], predictions_xgb_cv_hyperopt) * 100, 2))\n",
    "    precision_xgb_cv_hyperopt_list.append(round(precision_score(y.iloc[test_index], predictions_xgb_cv_hyperopt) * 100, 2))\n",
    "    recall_xgb_cv_hyperopt_list.append(round(recall_score(y.iloc[test_index], predictions_xgb_cv_hyperopt) * 100, 2))\n",
    "    f1_xgb_cv_hyperopt_list.append(round(f1_score(y.iloc[test_index], predictions_xgb_cv_hyperopt) * 100, 2))\n",
    "    roc_auc_xgb_cv_hyperopt_list.append(round(roc_auc_score(y.iloc[test_index], predictions_xgb_cv_hyperopt) * 100, 2))\n",
    "    \n",
    "# Compute average of metrics among the K-Folds\n",
    "accuracy_xgb_cv_hyperopt = round(np.mean(accuracy_xgb_cv_hyperopt_list), 2)\n",
    "precision_xgb_cv_hyperopt = round(np.mean(precision_xgb_cv_hyperopt_list), 2)\n",
    "recall_xgb_cv_hyperopt = round(np.mean(recall_xgb_cv_hyperopt_list), 2)\n",
    "f1_xgb_cv_hyperopt = round(np.mean(f1_xgb_cv_hyperopt_list), 2)\n",
    "roc_auc_xgb_cv_hyperopt = round(np.mean(roc_auc_xgb_cv_hyperopt_list), 2)\n",
    "cv_score_xgb_cv_hyperopt = round(cross_val_score(pipeline_xgb_cv_hyperopt, X, y, cv=stratified_kfold).mean() * 100, 2)\n",
    "\n",
    "print('Model accuracy: {}%'.format(accuracy_xgb_cv_hyperopt))\n",
    "print('Model precision: {}%'.format(precision_xgb_cv_hyperopt))\n",
    "print('Model recall: {}%'.format(recall_xgb_cv_hyperopt))\n",
    "print('Model f1 score: {}%'.format(f1_xgb_cv_hyperopt))\n",
    "print('Model ROC AUC: {}%'.format(roc_auc_xgb_cv_hyperopt))\n",
    "print('Model Cross Validation score: {}%'.format(cv_score_xgb_cv_hyperopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8281618-380b-4c93-bccc-ea77aa590d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' DataFrame\n",
    "performance.loc['xgboost_classifier_cv_hyperopt'] = [accuracy_xgb_cv_hyperopt, \n",
    "                                                     precision_xgb_cv_hyperopt, \n",
    "                                                     recall_xgb_cv_hyperopt, \n",
    "                                                     f1_xgb_cv_hyperopt, \n",
    "                                                     roc_auc_xgb_cv_hyperopt, \n",
    "                                                     cv_score_xgb_cv_hyperopt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d6307-1feb-42a8-ba69-44c91c84aba9",
   "metadata": {},
   "source": [
    "## Dense Neural Network\n",
    "\n",
    "A TensorFlow-based DNN with CUDA GPU training and Hyperparameters Optimization.\n",
    "The objective is to compare XGBoost with Deep Learning.\n",
    "\n",
    "<br>\n",
    "\n",
    "**NOTE:** KerasClassifier is a wrapper to use Keras models with Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed8890-84c0-4e71-9d37-7e71e12b7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model structure and compile\n",
    "def create_baseline():\n",
    "    \n",
    "    # Define model\n",
    "    model_dnn_tf = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(34, input_shape=(None, 34), activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model_dnn_tf.compile(loss='binary_crossentropy', \n",
    "                         optimizer='adam', \n",
    "                         metrics=['accuracy'])\n",
    "    \n",
    "    return model_dnn_tf             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468bea4-a913-4326-bb05-c8a4d6ff2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Do not use the wrapper but transform the feature beforehand\n",
    "\n",
    "# Define model\n",
    "model_dnn_tf = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(34, input_shape=(None, 34), activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model_dnn_tf.compile(loss='binary_crossentropy', \n",
    "                     optimizer='adam', \n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b76b69-e9e2-4dc5-83c8-5b414e31cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the Keras model\n",
    "model_dnn_tf_wrapped = KerasClassifier(model=create_baseline, \n",
    "                                       epochs=20, \n",
    "                                       batch_size=5, \n",
    "                                       verbose=1)\n",
    "\n",
    "# Define the Pipeline\n",
    "pipeline_dnn_tf = Pipeline([\n",
    "    ('feature_transformation', column_transformer),\n",
    "    ('dnn_tf', model_dnn_tf_wrapped)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b542e40-3b29-4f60-86ae-3d8925aff8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "pipeline_dnn_tf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d0845d-5081-4ab1-8d05-ec471b106ca6",
   "metadata": {},
   "source": [
    "# Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0926a19-8edd-4f90-b0fe-7020e925063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the models' performance\n",
    "figure = ex.bar(performance,\n",
    "                x=performance.index,\n",
    "                y=performance.columns.values,\n",
    "                labels={'index': 'Model', 'value': 'Performance'},\n",
    "                barmode='group',\n",
    "                title='Models Comparison',\n",
    "                template='plotly_dark')\n",
    "\n",
    "figure.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
